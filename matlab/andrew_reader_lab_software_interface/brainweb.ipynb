{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from caspyr.utils import H5Reader\n",
    "from caspyr.plotting import volshow\n",
    "from argopt import DictAttrWrap\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, cmap=\"Greys\", origin=\"lower\", title=None):\n",
    "    ax = plt.imshow(im, cmap=cmap, origin=origin)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = H5Reader(\"brainweb.raws/subject_04_sigma1_noise0.75_mMR.mat\", prefix=\"MultiMaps_Ref/\")\n",
    "dat.PET = H5Reader(\"brainweb.raws/subject_04_sigma1_noise1_mMR.mat\", prefix=\"MultiMaps_Ref/\").PET[:]\n",
    "d = dict()\n",
    "for i in dat.keys():\n",
    "    d[i] = getattr(dat, i)[:]\n",
    "del dat\n",
    "d = DictAttrWrap(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = slice(0, None), slice(100, -100), slice(100, -100)\n",
    "volshow([(i, getattr(d, i)[ROI]) for i in d.d.keys()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nReals = 5\n",
    "PAD = 4\n",
    "ROI = (19, 108), (128, 100+115), (120, 100+124)\n",
    "ROI = [slice(i - PAD, j + PAD) for i, j in ROI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(nPats, nReals=5, counts=None, ROI=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Intended for loading training data, e.g.:\n",
    "    >>> x, y = load(10, 1, counts=[30, 300])\n",
    "\n",
    "    @param counts  : [low, high] in millions [default: [3, 300]]\n",
    "    @param ROI  : ZXY (even though return is ZYX)\n",
    "    @return ndarray, shape (len(counts), nPats*nReals, D, H, W, Ch)\n",
    "      Ch is 3=<T1, PSF, PET> if `counts > 0`, 1=<TRUTH> otherwise.\n",
    "    \"\"\"\n",
    "    from caspyr.utils import Globber, H5Reader\n",
    "    from os import path\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from tqdm.auto import tqdm\n",
    "    glob = Globber.glob\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    DAT_ROOT = \"/data/cc16/apirl/o\"\n",
    "    #\"brainweb_PETpsf_1_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{:03d}.mat\"\n",
    "    subjects = sorted({i[47:49] for i in glob(path.join(\n",
    "        DAT_ROOT, \"reconAPIRL_brainweb_subject_*-S_1-NP_1-NT1_0.75-C_*_t3.mat\"))})\n",
    "    log.debug(\"subj:\" + ', '.join(subjects))\n",
    "\n",
    "    counts = counts or (3.01, 301)\n",
    "    ROI = ROI or (slice(0, None),) * 3\n",
    "    assert len(ROI) == 3\n",
    "    ROI = tuple(ROI)\n",
    "\n",
    "    res = [] # [counts, nReals + nReals_psf + T1 + PET, z,y,x]\n",
    "    for c in tqdm(counts, desc=\"counts\"):\n",
    "        vols = []\n",
    "        for subj in tqdm(subjects[:nPats], desc=\"subject\", leave=False):\n",
    "            d = path.join(DAT_ROOT,\n",
    "                \"reconAPIRL_brainweb_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3.mat\".format(\n",
    "                    subj, abs(c)*1e6))\n",
    "            d = H5Reader(d, prefix=\"reconAPIRL\")\n",
    "            if c < 0:\n",
    "                i = d.PET[ROI][None, :,:,:, None] * d.scale_factor[0,0]  # 1zyx1\n",
    "                i = np.repeat(i, min(d.mlem.shape[3], nReals), axis=-1)  # 1zyxN\n",
    "            else:\n",
    "                i = np.concatenate((\n",
    "                    d.mlem_psf[ROI + (slice(0, nReals),)][None],\n",
    "                    d.mlem[ROI + (slice(0, nReals),)][None],\n",
    "                ))  # 2zyxN\n",
    "                i = np.concatenate((np.repeat(d.T1[ROI][None, :,:,:, None], i.shape[-1], axis=-1), i))  # 3zyxN\n",
    "                #d.PET[ROI][None, :,:,:,None] * d.scale_factor[0,0]\n",
    "            i = i.transpose((4, 1,3,2, 0))  # Nzxy3\n",
    "            vols.append(i)\n",
    "        res.append(np.concatenate(vols))\n",
    "    return res\n",
    "\n",
    "# low->high\n",
    "#dat = load(10, nReals=nReals, counts=[3.01, 301], ROI=ROI) # 2, nReals*10, z, y, x, 3\n",
    "#np.savez_compressed('bweb-3.01-301.npz', x=dat[0], y=dat[1])\n",
    "\n",
    "dat = load(10, nReals=nReals, counts=[3.01, -3.01], ROI=ROI)\n",
    "np.savez_compressed('bweb-3.01-T.npz', x=dat[0], y=dat[1])\n",
    "\n",
    "#dat = load(10, nReals=nReals, counts=[30.1, -30.1], ROI=ROI)\n",
    "#np.savez_compressed('bweb-30.1-T.npz', x=dat[0], y=dat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias-var\n",
    "from argopt import DictAttrWrap\n",
    "from viper.utils import stats\n",
    "\n",
    "IDX = DictAttrWrap(dict(TRUE=0, T1=0, PSF=1, PET=2))\n",
    "\n",
    "tru = dat[1][:, :,:,:, IDX.TRUE]\n",
    "pet = dat[0][:, :,:,:, IDX.PET]\n",
    "psf = dat[0][:, :,:,:, IDX.PSF]\n",
    "\n",
    "#volshow(np.concatenate((tru[:4], psf[:4], pet[:4])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nReals):\n",
    "    reals = slice(i*nReals, (i + 1)*nReals)\n",
    "    #volshow(tru[reals])\n",
    "\n",
    "    \"\"\"\n",
    "    scale = 1 / (tru[reals][0] ** 2).mean()\n",
    "    bias = (((pet[reals].mean(axis=0) - tru[reals][0]) ** 2).mean() * scale) ** 0.5\n",
    "    stdv = ((pet[reals].var(axis=0, ddof=1)).mean() * scale) ** 0.5\n",
    "    # NOTE: use ddof=0 above to make nrmse = hypot(bias, stdv)\n",
    "    #nrmse = (((pet[reals] - tru[reals][0]) ** 2).mean() * scale) ** 0.5\n",
    "    \"\"\"\n",
    "    bias, stdv = stats.biasStdMask(pet[reals], tru[reals][:1])\n",
    "    print(\"pet\", bias, stdv, np.hypot(bias, stdv))\n",
    "\n",
    "    bias, stdv = stats.biasStdMask(psf[reals], tru[reals][:1])\n",
    "    print(\"psf\", bias, stdv, np.hypot(bias, stdv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biasStdv(nPats, nReals=5, counts=3.01, ROI=None, psf=False, **kwargs):\n",
    "    \"\"\"\n",
    "    >>> biasStdv(10, 1, counts=[30, 300])\n",
    "\n",
    "    @param counts  : in millions\n",
    "    @param ROI  : ZXY (even though return is ZYX)\n",
    "    @return ndarray, shape ((MLEM, PS), (bias, stdv), nItr)\n",
    "    \"\"\"\n",
    "    from caspyr.utils import Globber, H5Reader\n",
    "    from viper.utils import stats\n",
    "    from viper.constants import SIGMA2FWHM_MMRzyx\n",
    "    from viper.imsample import gauss\n",
    "    from os import path\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from tqdm.auto import tqdm, trange\n",
    "\n",
    "    glob = Globber.glob\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    DAT_ROOT = \"/data/cc16/apirl/o\"\n",
    "    #\"brainweb_PETpsf_1_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{:03d}.mat\"\n",
    "    subjects = sorted({i[47:49] for i in glob(path.join(\n",
    "        DAT_ROOT, \"reconAPIRL_brainweb_subject_*-S_1-NP_1-NT1_0.75-C_*_t3.mat\"))})\n",
    "    log.debug(\"subj:\" + ', '.join(subjects))\n",
    "\n",
    "    c = counts * 1e6\n",
    "    ROI = ROI or (slice(0, None),) * 3\n",
    "    assert len(ROI) == 3\n",
    "    ROI = tuple(ROI)\n",
    "\n",
    "    res = []  # [nPat, [MLEM, PostSmooth], nItr, [bias, stdv]]\n",
    "    for subj in tqdm(subjects[:nPats], unit=\"subject\", leave=False):\n",
    "        tru = path.join(DAT_ROOT,\n",
    "                \"reconAPIRL_brainweb_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3.mat\".format(\n",
    "                    subj, c))\n",
    "        tru = H5Reader(tru, prefix=\"reconAPIRL\")\n",
    "        tru = tru.PET[ROI][None] * tru.scale_factor[0,0]  # 1zxy\n",
    "\n",
    "        iters = glob(path.join(DAT_ROOT,\n",
    "            \"brainweb_PET_0_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_*.mat\".format(\n",
    "                subj, c)))\n",
    "        iters = [i[-7:-4] for i in iters]\n",
    "        log.debug(\"itr:\" + ' '.join(iters))\n",
    "\n",
    "        bs = []\n",
    "        for i in tqdm(iters, leave=False):\n",
    "            reals = glob(path.join(DAT_ROOT,\n",
    "                \"brainweb_PET{}_*_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{}.mat\".format(\n",
    "                \"psf\" if psf else \"\", subj, c, i)))\n",
    "            #log.debug(reals)\n",
    "            reals = [H5Reader(d).Img[ROI] for d in reals]  # Nzxy\n",
    "            #bs.append(stats.biasStd(np.array(reals), tru))\n",
    "            bs.append(stats.biasStdMask(np.array(reals), tru))\n",
    "        #res.append(bs)\n",
    "\n",
    "        last = np.array(reals)\n",
    "        bsPS = []\n",
    "        for i in tqdm(np.linspace(0, 25, num=len(iters)), unit_scale=25.0/len(iters),\n",
    "                      unit=\"mm\", desc=\"PS\", leave=False):\n",
    "            #bsPS.append(stats.biasStd(np.array(reals), tru))\n",
    "            sigma = [i / s for s in SIGMA2FWHM_MMRzyx]\n",
    "            bsPS.append(stats.biasStdMask(np.array([gauss(i, sigma) for i in last]), tru))\n",
    "        res.append((bs, bsPS))\n",
    "    return np.mean(res, axis=0).transpose((0, 2, 1))\n",
    "# low\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "bsPet = biasStdv(1, nReals=nReals, counts=3.01, psf=False, ROI=ROI)\n",
    "bsPsf = biasStdv(1, nReals=nReals, counts=3.01, psf=True, ROI=ROI)\n",
    "# high\n",
    "#bias, var = biasStdv(10, nReals=nReals, counts=3.01, ROI=ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(bsPet[0, 1], bsPet[0, 0], 'o-', ms=4, label=\"MLEM\")\n",
    "ax.plot(bsPsf[0, 1], bsPsf[0, 0], 'o-', ms=4, label=\"MLEM+RM\")\n",
    "\n",
    "i = np.hypot(bsPet[1, 1], bsPet[1, 0]); i = np.where(i == i.min())[0]\n",
    "ax.plot(bsPet[1, 1], bsPet[1, 0], 'ko-', markevery=i, label=\"PS up to 25mm\")\n",
    "\n",
    "i = np.hypot(bsPsf[1, 1], bsPsf[1, 0]); i = np.where(i == i.min())[0]\n",
    "ax.plot(bsPsf[1, 1], bsPsf[1, 0], 'ko-', markevery=i)\n",
    "\n",
    "plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "plt.ylabel(r\"Bias, $b$/[%]\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
