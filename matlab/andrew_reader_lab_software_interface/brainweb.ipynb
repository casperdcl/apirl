{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(\n",
    "        per_process_gpu_memory_fraction=0.4, visible_device_list=\"0\"))))\n",
    "\n",
    "import numpy as np\n",
    "from caspyr.utils import H5Reader, glob\n",
    "from caspyr.plotting import volshow\n",
    "from argopt import DictAttrWrap\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, cmap=\"Greys\", origin=\"lower\", title=None):\n",
    "    ax = plt.imshow(im, cmap=cmap, origin=origin)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROI = slice(0, None), slice(100, -100), slice(100, -100)\n",
    "\n",
    "dat = H5Reader(\"brainweb.raws/subject_04_sigma1_noise0.75_mMR.mat\", prefix=\"MultiMaps_Ref/\")\n",
    "dat.PET = H5Reader(\"brainweb.raws/subject_04_sigma1_noise1_mMR.mat\", prefix=\"MultiMaps_Ref/\").PET[:]\n",
    "d = dict()\n",
    "for i in dat.keys():\n",
    "    d[i] = getattr(dat, i)[ROI]\n",
    "del dat\n",
    "d = DictAttrWrap(d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "volshow([(i, getattr(d, i)) for i in d.d.keys()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstructions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROI = slice(0, None), slice(100, -100), slice(100, -100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#dat = H5Reader(\"output/reconAPIRL_real-AD_1.mat\", prefix=\"reconAPIRL/\")\n",
    "d = []\n",
    "#for i in tqdm(glob(\"/data/cc16/apirl/osem21/brainweb_PET_0_subject_04-S_1-NP_1-NT1_0.75-C_3.01e+08_t3_*.mat\")):\n",
    "#for i in tqdm(glob(\"/data/cc16/apirl/osem21/brainweb_PETpsf_1_subject_04-S_1-NP_1-NT1_0.75-C_3.01e+08_t3_*.mat\")):\n",
    "#for i in tqdm(glob(\"/data/cc16/apirl/o/brainweb_PET_0_subject_04-S_1-NP_1-NT1_0.75-C_3.01e+08_t3_*.mat\")):\n",
    "for i in tqdm(glob(\"/data/cc16/apirl/o/brainweb_PETpsf_1_subject_04-S_1-NP_1-NT1_0.75-C_3.01e+08_t3_*.mat\")):\n",
    "    dat = H5Reader(i)\n",
    "    d.append(dat.Img[ROI])\n",
    "    del dat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "volshow([i for i in d[::10]]);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dFull = H5Reader(\"/data/cc16/apirl/o/reconAPIRL_brainweb_subject_04-S_1-NP_1-NT1_0.75-C_3.01e+08_t3.mat\",\n",
    "                 prefix=\"reconAPIRL\")\n",
    "\n",
    "dFull = np.concatenate((\n",
    "    dFull.mlem[ROI],\n",
    "    dFull.T1[ROI][:,:,:,None],\n",
    "    dFull.PET[ROI][:,:,:,None] * dFull.scale_factor[0,0]), axis=3).transpose((3, 0,1,2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "volshow(dFull);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dat = H5Reader(\"output/reconAPIRL_real-AD_1.mat\", prefix=\"reconAPIRL\")\n",
    "d = dict()\n",
    "for i in dat.keys():\n",
    "    d[i] = getattr(dat, i)[:]\n",
    "del dat\n",
    "d = DictAttrWrap(d)\n",
    "d.uMap = np.fromfile('output/data-LM-00-umap-AD_1.v', dtype=np.float32).reshape(127, 344, 344).transpose((0, 2, 1))\n",
    "\n",
    "ROI = slice(0, None), slice(100, -100), slice(100, -100)\n",
    "volshow([(i, getattr(d, i)[ROI]) for i in \"PET T1 PET_psf uMap\".split()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bias-stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nReals = 5\n",
    "PAD = 4\n",
    "ROI = (19, 108), (128, 100+115), (120, 100+124)\n",
    "ROI = [slice(i - PAD, j + PAD) for i, j in ROI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(nPats, nReals=5, counts=None, ROI=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Intended for loading training data, e.g.:\n",
    "    >>> x, y = load(10, 1, counts=[30, 300])\n",
    "\n",
    "    @param counts  : [low, high] in millions [default: [3, 300]]\n",
    "    @param ROI  : ZXY (even though return is ZYX)\n",
    "    @return ndarray, shape (len(counts), nPats*nReals, D, H, W, Ch)\n",
    "      Ch is 3=<T1, PSF, PET> if `counts > 0`, 1=<TRUTH> otherwise.\n",
    "    \"\"\"\n",
    "    from caspyr.utils import Globber, H5Reader\n",
    "    from os import path\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from tqdm.auto import tqdm\n",
    "    glob = Globber.glob\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    DAT_ROOT = \"/data/cc16/apirl/o\"\n",
    "    #\"brainweb_PETpsf_1_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{:03d}.mat\"\n",
    "    subjects = sorted({i[47:49] for i in glob(path.join(\n",
    "        DAT_ROOT, \"reconAPIRL_brainweb_subject_*-S_1-NP_1-NT1_0.75-C_*_t3.mat\"))})\n",
    "    log.debug(\"subj:\" + ', '.join(subjects))\n",
    "\n",
    "    counts = counts or (3.01, 301)\n",
    "    ROI = ROI or (slice(0, None),) * 3\n",
    "    assert len(ROI) == 3\n",
    "    ROI = tuple(ROI)\n",
    "\n",
    "    res = [] # [counts, nReals + nReals_psf + T1 + PET, z,y,x]\n",
    "    for c in tqdm(counts, desc=\"counts\"):\n",
    "        vols = []\n",
    "        for subj in tqdm(subjects[:nPats], desc=\"subject\", leave=False):\n",
    "            d = path.join(DAT_ROOT,\n",
    "                \"reconAPIRL_brainweb_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3.mat\".format(\n",
    "                    subj, abs(c)*1e6))\n",
    "            d = H5Reader(d, prefix=\"reconAPIRL\")\n",
    "            if c < 0:\n",
    "                i = d.PET[ROI][None, :,:,:, None] * d.scale_factor[0,0]  # 1zyx1\n",
    "                i = np.repeat(i, min(d.mlem.shape[3], nReals), axis=-1)  # 1zyxN\n",
    "            else:\n",
    "                i = np.concatenate((\n",
    "                    d.mlem_psf[ROI + (slice(0, nReals),)][None],\n",
    "                    d.mlem[ROI + (slice(0, nReals),)][None],\n",
    "                ))  # 2zyxN\n",
    "                i = np.concatenate((np.repeat(d.T1[ROI][None, :,:,:, None], i.shape[-1], axis=-1), i))  # 3zyxN\n",
    "                #d.PET[ROI][None, :,:,:,None] * d.scale_factor[0,0]\n",
    "            i = i.transpose((4, 1,3,2, 0))  # Nzxy3\n",
    "            vols.append(i)\n",
    "        res.append(np.concatenate(vols))\n",
    "    return res\n",
    "\n",
    "# low->high\n",
    "#dat = load(10, nReals=nReals, counts=[3.01, 301], ROI=ROI) # 2, nReals*10, z, y, x, 3\n",
    "#np.savez_compressed('bweb-3.01-301.npz', x=dat[0], y=dat[1])\n",
    "\n",
    "dat = load(10, nReals=nReals, counts=[3.01, -3.01], ROI=ROI)\n",
    "np.savez_compressed('bweb-3.01-T.npz', x=dat[0], y=dat[1])\n",
    "\n",
    "#dat = load(10, nReals=nReals, counts=[30.1, -30.1], ROI=ROI)\n",
    "#np.savez_compressed('bweb-30.1-T.npz', x=dat[0], y=dat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias-var\n",
    "from argopt import DictAttrWrap\n",
    "from viper.utils import stats\n",
    "import functools\n",
    "\n",
    "IDX = DictAttrWrap(dict(TRUE=0, T1=0, PSF=1, PET=2))\n",
    "load_model = functools.partial(tf.keras.models.load_model,\n",
    "    custom_objects=dict(lossGen=tf.keras.losses.mse, nrmse=tf.keras.losses.mse))\n",
    "modelGen = load_model(\"modelGen-3.01-T.h5\")\n",
    "modelGAN = load_model(\"modelGAN-3.01-T.h5\")\n",
    "\n",
    "tru = dat[1][:, :,:,:, IDX.TRUE]\n",
    "pet = dat[0][:, :,:,:, IDX.PET]\n",
    "psf = dat[0][:, :,:,:, IDX.PSF]\n",
    "net = modelGen.predict(dat[0])[:, :,:,:, IDX.TRUE]\n",
    "gan = modelGAN.predict(dat[0])[:, :,:,:, IDX.TRUE]\n",
    "\n",
    "#volshow(np.concatenate((tru[:4], psf[:4], pet[:4])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nReals):\n",
    "    reals = slice(i*nReals, (i + 1)*nReals)\n",
    "    #volshow(tru[reals])\n",
    "\n",
    "    \"\"\"\n",
    "    scale = 1 / (tru[reals][0] ** 2).mean()\n",
    "    bias = (((pet[reals].mean(axis=0) - tru[reals][0]) ** 2).mean() * scale) ** 0.5\n",
    "    stdv = ((pet[reals].var(axis=0, ddof=1)).mean() * scale) ** 0.5\n",
    "    # NOTE: use ddof=0 above to make nrmse = hypot(bias, stdv)\n",
    "    #nrmse = (((pet[reals] - tru[reals][0]) ** 2).mean() * scale) ** 0.5\n",
    "    \"\"\"\n",
    "    bias, stdv = stats.biasStdMask(pet[reals], tru[reals][:1])\n",
    "    print(\"pet\", bias, stdv, np.hypot(bias, stdv))\n",
    "\n",
    "    bias, stdv = stats.biasStdMask(psf[reals], tru[reals][:1])\n",
    "    print(\"psf\", bias, stdv, np.hypot(bias, stdv))\n",
    "\n",
    "    bias, stdv = stats.biasStdMask(net[reals] * tru[reals][:1].std(), tru[reals][:1])\n",
    "    print(\"net\", bias, stdv, np.hypot(bias, stdv))\n",
    "\n",
    "    bias, stdv = stats.biasStdMask(gan[reals] * tru[reals][:1].std(), tru[reals][:1])\n",
    "    print(\"gan\", bias, stdv, np.hypot(bias, stdv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biasStdv(nPats, nReals=5, counts=3.01, ROI=None, **kwargs):\n",
    "    \"\"\"\n",
    "    >>> biasStdv(10, 1, counts=[30, 300])\n",
    "\n",
    "    @param counts  : in millions\n",
    "    @param ROI  : ZXY (even though return is ZYX)\n",
    "    @return ndarray, shape ((MLEM, MLEM+PS, PSF, PSF+PS), (bias, stdv), nItr)\n",
    "    \"\"\"\n",
    "    from caspyr.utils import Globber, H5Reader\n",
    "    from viper.utils.stats import biasStdMask  # biasStd as biasStdMask\n",
    "    from viper.constants import SIGMA2FWHM_MMRzyx\n",
    "    from viper.imsample import gauss\n",
    "    from os import path\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from tqdm.auto import tqdm, trange\n",
    "\n",
    "    glob = Globber.glob\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    DAT_ROOT = \"/data/cc16/apirl/o\"\n",
    "    #\"brainweb_PETpsf_1_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{:03d}.mat\"\n",
    "    subjects = sorted({i[47:49] for i in glob(path.join(\n",
    "        DAT_ROOT, \"reconAPIRL_brainweb_subject_*-S_1-NP_1-NT1_0.75-C_*_t3.mat\"))})\n",
    "    log.debug(\"subj:\" + ', '.join(subjects))\n",
    "\n",
    "    c = counts * 1e6\n",
    "    ROI = ROI or (slice(0, None),) * 3\n",
    "    assert len(ROI) == 3\n",
    "    ROI = tuple(ROI)\n",
    "\n",
    "    res = []  # [nPat, [MLEM, MLEM+PS, PSF, PSF+PS], nItr, [bias, stdv]]\n",
    "    for subj in tqdm(subjects[:nPats], unit=\"subject\", leave=True):\n",
    "        tru = path.join(DAT_ROOT,\n",
    "                \"reconAPIRL_brainweb_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3.mat\".format(\n",
    "                    subj, c))\n",
    "        tru = H5Reader(tru, prefix=\"reconAPIRL\")\n",
    "        tru = tru.PET[ROI][None] * tru.scale_factor[0,0]  # 1zxy\n",
    "\n",
    "        iters = glob(path.join(DAT_ROOT,\n",
    "            \"brainweb_PET_0_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_*.mat\".format(\n",
    "                subj, c)))\n",
    "        iters = [i[-7:-4] for i in iters]\n",
    "        log.debug(\"itr:\" + ' '.join(iters))\n",
    "\n",
    "        stage = tqdm(total=2, desc=\"Stage\", leave=False)\n",
    "\n",
    "        bs = []\n",
    "        bsPSF = []\n",
    "        for i in tqdm(iters, desc=\"Iterations\", leave=False):\n",
    "            reals = glob(path.join(DAT_ROOT,\n",
    "                \"brainweb_PET_*_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{}.mat\".format(\n",
    "                    subj, c, i)))\n",
    "            #log.debug(reals)\n",
    "            reals = [H5Reader(d).Img[ROI] for d in reals]  # Nzxy\n",
    "            bs.append(biasStdMask(np.array(reals), tru))\n",
    "\n",
    "            realsPSF = glob(path.join(DAT_ROOT,\n",
    "                \"brainweb_PETpsf_*_subject_{}-S_1-NP_1-NT1_0.75-C_{:.3g}_t3_{}.mat\".format(\n",
    "                    subj, c, i)))\n",
    "            realsPSF = [H5Reader(d).Img[ROI] for d in realsPSF]  # Nzxy\n",
    "            bsPSF.append(biasStdMask(np.array(realsPSF), tru))\n",
    "        #res.append(bs)\n",
    "        stage.update()\n",
    "\n",
    "        bsPS = []\n",
    "        bsPSF_PS = []\n",
    "        last = np.array(reals)\n",
    "        lastPSF = np.array(realsPSF)\n",
    "        for i in tqdm(np.linspace(0, 25, num=len(iters)), unit_scale=25.0/len(iters),\n",
    "                      unit=\"mm\", desc=\"PS\", leave=False):\n",
    "            sigma = [i / s for s in SIGMA2FWHM_MMRzyx]\n",
    "            bsPS.append(biasStdMask(np.array([gauss(i, sigma) for i in last]), tru))\n",
    "            bsPSF_PS.append(biasStdMask(np.array([gauss(i, sigma) for i in lastPSF]), tru))\n",
    "        stage.update()\n",
    "\n",
    "        stage.close()\n",
    "        res.append((bs, bsPS, bsPSF, bsPSF_PS))\n",
    "    return np.mean(res, axis=0).transpose((0, 2, 1))\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "# low\n",
    "bsPet = biasStdv(1, nReals=nReals, counts=3.01, psf=False, ROI=ROI)\n",
    "# high\n",
    "#bias, var = biasStdv(10, nReals=nReals, counts=301, ROI=ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(bsPet[0, 1], bsPet[0, 0], 'o-', ms=4, label=\"MLEM\")\n",
    "ax.plot(bsPet[2, 1], bsPet[2, 0], 'o-', ms=4, label=\"MLEM+RM\")\n",
    "\n",
    "i = np.hypot(bsPet[1, 1], bsPet[1, 0]); i = np.where(i == i.min())[0]\n",
    "ax.plot(bsPet[1, 1], bsPet[1, 0], 'ko-', markevery=i, label=\"PS up to 25mm\")\n",
    "\n",
    "i = np.hypot(bsPet[3, 1], bsPet[3, 0]); i = np.where(i == i.min())[0]\n",
    "ax.plot(bsPet[3, 1], bsPet[3, 0], 'ko-', markevery=i)\n",
    "\n",
    "plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "plt.ylabel(r\"Bias, $b$/[%]\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
