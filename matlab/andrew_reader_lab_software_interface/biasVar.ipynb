{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import re\n",
    "from os import path\n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import strftime\n",
    "from scipy.ndimage.filters import gaussian_filter as gauss\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.simplefilter(\"ignore\", category=TqdmExperimentalWarning)\n",
    "    from tqdm.auto import tqdm, trange\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"numpy.dtype size changed\", module=\"h5py\")\n",
    "from caspyr.utils import H5Reader, Globber, glob\n",
    "\n",
    "from viper.plot_style import toLab, plt_kwargs, savefig, plt_title, font_prop\n",
    "#from viper.utils.stats import movingAvg, nrmse, biasStd, biasStdMask\n",
    "#import viper.utils.stats as vus; reload(vus); nrmse=vus.nrmse; biasStd = vus.biasStd  # , biasStdMask\n",
    "from viper.utils.stats import nrmse, biasStd, biasStdMask\n",
    "from viper.utils.mlab import imguidedfilter\n",
    "from viper.constants import SIGMA2FWHM_MMR\n",
    "#SIGMA2FWHM_MMR = (8 * np.log(2)) ** .5 * 2.08626\n",
    "from viper.imsample import nonLocMn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fntScl = 1.5\n",
    "def imshow(im, cmap=\"Greys\", origin=\"lower\", title=None, **kwargs):\n",
    "    ax = plt.imshow(im, cmap=cmap, origin=origin, **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "def autoROI(im):\n",
    "    \"\"\"return bounding box tuple(slice) of non-zero elements\"\"\"\n",
    "    inds = np.array(im.nonzero())\n",
    "    mins = inds.min(axis=1)\n",
    "    maxs = inds.max(axis=1)\n",
    "    return tuple(slice(i, j) for i, j in zip(mins, maxs))\n",
    "\n",
    "def imNorm(im, assumeZeroMin=True):\n",
    "    \"\"\"in-place, average 1 count/voxel\"\"\"\n",
    "    if not assumeZeroMin:\n",
    "        im -= im.min()\n",
    "    im *= im.size / im.max()\n",
    "    return im\n",
    "\n",
    "def flatMask(im, thresh=50, hw=1):\n",
    "    \"\"\"\n",
    "    thresh  : int, percentile\n",
    "    hw  : int, half width\n",
    "    \"\"\"\n",
    "    from scipy.signal import convolve\n",
    "    m = np.ones([2*hw+1] * im.ndim) * -1\n",
    "    m[hw, hw] = m.size - 1\n",
    "    edges = np.abs(convolve(im, m, mode='same'))\n",
    "    msk = edges < np.percentile(edges.flat, thresh)  # high pass\n",
    "    msk *= im > np.percentile(im[im > 0].flat, 100 - thresh)  # low pass\n",
    "    return msk\n",
    "\n",
    "def isinstanceStr(s, cls):\n",
    "    \"\"\"@return isinstance(cls(s), cls) except: False\"\"\"\n",
    "    try:\n",
    "        return isinstance(cls(s), cls)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globber = Globber(\n",
    "    (\"meta0\", \"output/[0-9]+/brainweb_\", \"output/*/brainweb_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_[0-9]+_subject_\", \"_*_subject_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta6\", \"-S_\", \"-S_\"),\n",
    "    (\"sigma\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta7\", \"-NP_\", \"-NP_\"),\n",
    "    (\"fsPET\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta8\", \"-NT1_\", \"-NT1_\"),\n",
    "    (\"fsT1\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"-?[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"-?[0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskThresh = 50\n",
    "PAD = 3\n",
    "from viper.classifier.data.bw import ROI as ROI_BW  # zxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGnd(fn, debug=False):\n",
    "    # ground truth image\n",
    "    counts = globber.split(fn)[globber[\"counts\"]]\\\n",
    "        .replace('-', \"-?\").replace('+', '\\\\+').replace('.', '\\\\.')\n",
    "    files = globber.filterReUnlike(fn, it=\"000\") or globber.filterReUnlike(\n",
    "        fn, meta0=None, meta1=None, rm=None, it=\"000\", counts=counts)  # counts=None\n",
    "    if not files:\n",
    "        raise IOError(\"Could not find truth for:%s\" % fn)\n",
    "    if debug:\n",
    "        #ROI = autoROI(H5Reader(files[0]).tAct[:])  # non-zero ROI\n",
    "        ROI = ROI_BW\n",
    "        imGnd = H5Reader(files[0]).tAct[ROI]\n",
    "        tmp = [(imGnd == H5Reader(i).tAct[ROI]).all() for i in tqdm(files, desc=\"debug\")]\n",
    "        #print(len(tmp), files)\n",
    "        if not all(tmp):\n",
    "            raise ValueError(\"mismatched ground truths:\" + p)\n",
    "    return files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globber.partsVals[:-2] + ['000 -> 300', globber.partsVals[-1]]\n",
    "rms = globber.partsVals[globber[\"rm\"]]\n",
    "pats = globber.partsVals[globber[\"pat\"]]  # int\n",
    "counts = globber.partsVals[globber[\"counts\"]]  # float\n",
    "tums = globber.partsVals[globber[\"tum\"]]  # int\n",
    "its = globber.partsVals[globber[\"it\"]]  # int\n",
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = \"\"\"\n",
    "54\n",
    "\"\"\".strip().split()\n",
    "counts = [\"%.3g\" % (i * 1e6) for i in [4.3, 43, 301]]\n",
    "tums=['1']\n",
    "#brainweb_PET_*_54-*_4.3*_t1_001.mat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#counts = filter(lambda s: s.startswith('-'), counts)\n",
    "tums=['0']; rms=[\"PETpsf\"]; counts=['4.3e+07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varDict = {}\n",
    "bsqDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputPkl = \"output/biasVar.pkl\"\n",
    "#outputPkl = \"output/biasVar-flat.pkl\"\n",
    "outputPkl = \"output/biasVar-brainweb.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputPkl) as fd:\n",
    "    bsqDict, varDict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "for rm in tqdm(rms, desc=\"RM\"):\n",
    "    for pat in tqdm(pats, desc=\"Patient\"):\n",
    "        for cnt in tqdm(counts, desc=\"Counts\"):\n",
    "            for tum in tqdm(tums, desc=\"Tumours\"):\n",
    "                files = globber.filterRe(\n",
    "                    escape=True,\n",
    "                    rm=rm, pat=pat, counts=cnt, tum=tum,\n",
    "                    it=\"001\")\n",
    "                if not files:\n",
    "                    print(\"cannot find globber files\", rm, pat, cnt, tum)\n",
    "                    continue\n",
    "\n",
    "                # per-iteration results vectors\n",
    "                bsq = []\n",
    "                var = []\n",
    "                # ground truth image`\n",
    "                imGnd = H5Reader(getGnd(files[0]))\n",
    "                #ROI = autoROI(imGnd.tAct[:])  # non-zero ROI\n",
    "                #ROI = (slice(3, -3),)*3\n",
    "                ROI = ROI_BW\n",
    "                ROI = tuple(slice(i.start + 3, i.stop - 3) for i in ROI)\n",
    "                ##half = (ROI[0].stop - ROI[0].start) // 2 + ROI[0].start\n",
    "                ##ROI[0] = slice(half - 3, half + 3)\n",
    "                imT1 = imGnd.T1[ROI]\n",
    "                imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "                #imGnd = imNorm(imGnd)\n",
    "                # imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "                ####mask = flatMask(imGnd, maskThresh)\n",
    "                #mask = imGnd > 0\n",
    "                imGndPreMask = imGnd\n",
    "                #imT1PreMask = imT1\n",
    "                #imGnd = imGnd[mask]\n",
    "                #imT1 = imT1[mask]\n",
    "                #imScale = (imGnd ** 2).mean()\n",
    "                # pre-allocate one set of realisations [R, X, Y, Z]\n",
    "                #ims = np.zeros((len(parts),) + imGnd.shape, dtype=imGnd.dtype)\n",
    "                #ims = np.zeros((len(files), imGnd.size), dtype=imGnd.dtype)\n",
    "                with tqdm(total=len(its),\n",
    "                          desc=\"%d reals, %.3g scale\" % (len(files), imGnd.sum())) as tIters:\n",
    "                  it = 1\n",
    "                  while True:\n",
    "                    usedfiles = filter(path.exists, [p[:-7] + \"%03d.mat\" % it for p in files])\n",
    "                    if not usedfiles:\n",
    "                        if it > 1:\n",
    "                            usedfiles = filter(path.exists, [p[:-7] + \"%03d.mat\" % (it - 1) for p in files])\n",
    "                            last_it_ims = [H5Reader(p).Img[ROI] for p in usedfiles]\n",
    "                        break\n",
    "                    #if len(ims) != len(usedfiles):\n",
    "                    #    log.warn(\"altering preallocation\")\n",
    "                    #    ims = np.zeros((len(usedfiles), imGnd.size), dtype=imGnd.dtype)\n",
    "                    #for i, p in enumerate(tqdm(usedfiles, desc=\"realisations\", disable=True)):\n",
    "                    #    #ims[i] = imNorm(H5Reader(''.join(p)).Img[ROI])[mask]\n",
    "                    #    ims[i] = H5Reader(p).Img[ROI][mask]\n",
    "                    HACK_SKIP = False\n",
    "                    if not HACK_SKIP:\n",
    "                        last_it_ims = [H5Reader(p).Img[ROI] for p in usedfiles]\n",
    "                        bias, std = biasStdMask(np.array(last_it_ims), imGndPreMask[None])\n",
    "                        bsq.append((bias / 100) ** 2)\n",
    "                        var.append((std / 100) ** 2)\n",
    "                        # ims = [i[mask] for i in last_it_ims]\n",
    "                        # imMean = np.mean(ims, axis=0)\n",
    "                        # #imMean = ims.mean(axis=0)\n",
    "                        # #bsq.append(((imMean - imGnd) / imGnd).mean())\n",
    "                        # #var.append((np.std(ims, axis=0, ddof=1) / imMean).mean())\n",
    "                        # bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                        # #var.append((np.var(ims, axis=0, ddof=min(1, len(ims)-1))).mean() / imScale)\n",
    "                        # var.append((np.var(ims, axis=0)).mean() / imScale)\n",
    "                        tIters.set_postfix(\n",
    "                            # N.B: mseTest will be nonzero due to var(..., ddof=1)\n",
    "                            # mseTest = ((ims - imGnd) ** 2).mean() / imScale - bsq[-1] - var[-1],\n",
    "                            mse=bsq[-1] + var[-1], bsq=bsq[-1], var=var[-1], refresh=False)\n",
    "                    tIters.update()\n",
    "                    it += 1\n",
    "                #key = list(globber.valRe.findall(files[0])[0])\n",
    "                #key[globber[\"it\"]] = \"\"\n",
    "                #key = ':'.join(key)\n",
    "                #key = ':'.join((rm, pat, cnt, tum))\n",
    "                key = rm, pat, cnt, tum\n",
    "                if not HACK_SKIP:\n",
    "                    bsqDict[key] = np.array(bsq)\n",
    "                    varDict[key] = np.array(var)\n",
    "                if 0 < float(cnt) < 301e6:  # and \"psf\" in rm:\n",
    "                    num = it - 1  # len(bsq)\n",
    "                    last_it_ims = np.array(last_it_ims)\n",
    "                    if True:  # post-smoothing\n",
    "                        bsq = []\n",
    "                        var = []\n",
    "                        for s in tqdm(np.linspace(0, 25, num=num) / SIGMA2FWHM_MMR, desc=\"PS\"):\n",
    "                            ims = [gauss(im, s) for im in last_it_ims]\n",
    "                            bias, std = biasStdMask(np.array(ims), imGndPreMask[None])\n",
    "                            bsq.append((bias / 100) ** 2)\n",
    "                            var.append((std / 100) ** 2)\n",
    "                            # ims = [gauss(im, s)[mask] for im in last_it_ims]\n",
    "                            # imMean = np.mean(ims, axis=0)\n",
    "                            # bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                            # #var.append((np.var(ims, axis=0, ddof=min(1, len(ims)-1))).mean() / imScale)\n",
    "                            # var.append((np.var(ims, axis=0)).mean() / imScale)\n",
    "                            #if np.all(last_it_ims == ims):\n",
    "                            #    print(s)\n",
    "                        key1 = key[0], key[1] + \"PS\", key[2], key[3]\n",
    "                        bsqDict[key1] = np.array(bsq)\n",
    "                        varDict[key1] = np.array(var)\n",
    "                    if True:  # guided-filtering\n",
    "                        nLMRad = 2\n",
    "                        half = len(mask) // 2\n",
    "                        #ROI_GF = slice(half, half + 1)\n",
    "                        ROI_GF = slice(half - nLMRad, half + nLMRad)\n",
    "                        #ROI_GF = slice(0, None)\n",
    "                        #maskGF = mask[ROI_GF]\n",
    "                        imGndPreMaskGF = imGndPreMask[ROI_GF]\n",
    "                        #imGndGF = imGndPreMaskGF[maskGF]\n",
    "                        #imScaleGF = (imGndGF ** 2).mean()\n",
    "                        bsq = []\n",
    "                        var = []\n",
    "\n",
    "                        from scipy.interpolate import interp1d\n",
    "                        #eps = np.logspace(-13, 0, num=num)\n",
    "                        eps = np.logspace(-5, 0, num=num)\n",
    "                        #eps = np.linspace(1e-5, 1, num=num)\n",
    "                        epsUndersamp = np.logspace(np.log10(eps[0]), np.log10(eps[-1]), num=num // 10)\n",
    "                        #epsUndersamp = np.linspace(eps[0], eps[-1], num=10)\n",
    "                        print(usedfiles[-1])\n",
    "                        with tqdm(epsUndersamp, desc=\"GF\") as prog:\n",
    "                          for s in prog:\n",
    "                            ims = [#imguidedfilter(im[ROI_GF], imT1[ROI_GF],\n",
    "                                   #               float(s), 3, progress='disable')[maskGF]\n",
    "                                   nonLocMn(im[ROI_GF], imT1[ROI_GF], r=nLMRad, sigma=float(s))\n",
    "                                   for im in tqdm(last_it_ims, desc=\"guidedfilter\", leave=False)]\n",
    "                            bias, std = biasStdMask(np.array(ims), imGndPreMaskGF[None])\n",
    "                            bsq.append((bias / 100) ** 2)\n",
    "                            var.append((std / 100) ** 2)\n",
    "                            # imMean = np.mean(ims, axis=0)\n",
    "                            # bsq.append(((imMean - imGndGF) ** 2).mean() / imScaleGF)\n",
    "                            # #var.append((np.var(ims, axis=0, ddof=min(1, len(ims)-1))).mean() / imScaleGF)\n",
    "                            # var.append((np.var(ims, axis=0)).mean() / imScaleGF)\n",
    "                            prog.set_postfix(\n",
    "                                rmse=(bsq[-1] + var[-1])**0.5, bsq=bsq[-1], var=var[-1], s=s, refresh=False)\n",
    "                        bsq = interp1d(epsUndersamp, bsq, kind='linear')(eps)\n",
    "                        var = interp1d(epsUndersamp, var, kind='linear')(eps)\n",
    "                        # prefix raw\n",
    "                        # ims = [i[mask] for i in last_it_ims]\n",
    "                        # bsq[0] = ((np.mean(ims, axis=0) - imGnd) ** 2).mean() / imScale\n",
    "                        # var[0] = (np.var(ims, axis=0)).mean() / imScale\n",
    "                        bias, std = biasStdMask(np.array(last_it_ims), imGndPreMask[None])\n",
    "                        bsq[0] = (bias / 100) ** 2\n",
    "                        var[0] = (std / 100) ** 2\n",
    "                        # save\n",
    "                        key1 = key[0], key[1] + \"GF\", key[2], key[3]\n",
    "                        bsqDict[key1] = np.array(bsq)\n",
    "                        varDict[key1] = np.array(var)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(outputPkl, \"w\") as fd:\n",
    "    pickle.dump((bsqDict, varDict), fd, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(varDict.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "keep = [k for k in varDict.keys() if all(i in j for (i, j) in zip(k, [rms, pats, counts, tums]))]\n",
    "bsqDict = {k: bsqDict[k] for k in keep}\n",
    "varDict = {k: varDict[k] for k in keep}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rmPatCnt = []  # average across tumours\n",
    "for rm, pat, cnt in {i[:3] for i in varDict.keys()}:\n",
    "    avgBiasVar = [\n",
    "        np.array([src[k] for k in src if k[:3]==(rm, pat, cnt)]).mean(axis=0)\n",
    "        for src in (bsqDict, varDict)]\n",
    "    rmPatCnt.append((rm, pat, cnt, avgBiasVar))\n",
    "    #rmPatCnt.setdefault(i1, {}).setdefault(i3, {})[float(i5)] = res.mean(axis=0)\n",
    "rmPatCnt.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsqVarAvg = {}  # average across tumours\n",
    "for rm, pat, cnt in {i[:3] for i in varDict.keys() if isinstanceStr(i[1], int)}:\n",
    "    # dimensions: bias|var, realisation, iteration\n",
    "    avgBiasVar = [\n",
    "        [src[k] for k in src if k[:3]==(rm, pat, cnt)]\n",
    "        for src in (bsqDict, varDict)]\n",
    "    nitMax = max([len(i) for i in avgBiasVar[0]])\n",
    "    avgBiasVar = np.array([[np.pad(i, (0, nitMax-len(i)), 'constant') for i in src]\n",
    "                           for src in avgBiasVar])\n",
    "    # slightly risky as `0` may not signify padding:\n",
    "    nitScale = avgBiasVar.astype(np.bool).astype('i4').sum(axis=1)\n",
    "    nitScale[nitScale==0] = 1\n",
    "    avgBiasVar = avgBiasVar.sum(axis=1) / nitScale\n",
    "    bsqVarAvg[(rm, pat, cnt)] = avgBiasVar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# noise-free debug\n",
    "plt.figure(figsize=(16, 9), dpi=60); plt.title(\"Noise-free\")\n",
    "y = bsqDict[('PET', '54', '-3.01e+08', '0')]\n",
    "plt.plot(y ** 0.5 * 100, label=\"MLEM\")\n",
    "i = y.argmin()\n",
    "plt.scatter([i], [y[i] ** 0.5 * 100])\n",
    "plt.plot(bsqDict[('PETpsf', '54', '-3.01e+08', '0')] ** 0.5 * 100, label=\"PSF\")\n",
    "plt.xlabel(r\"Iteration\")\n",
    "plt.ylabel(\"NRMSE/[%]\")\n",
    "plt.ylim(None, 46)\n",
    "plt.xlim(0, None)\n",
    "plt.legend()\n",
    "\n",
    "_, axs = plt.subplots(1, 2)\n",
    "axs = axs.flat\n",
    "plt.sca(axs[0])\n",
    "d = H5Reader(globber.filterRe(counts=\"-3.01e+08\", it=\"%03d\" % i, rm=\"PET\", escape=True)[0])\n",
    "plt.title(\"MLEM %dit\" % i)\n",
    "imshow(d.Img[64].T[::-1][100:-100, 100:-100])\n",
    "plt.sca(axs[1])\n",
    "d = H5Reader(globber.filterRe(counts=\"-3.01e+08\", it=\"999\", rm=\"PETpsf\", escape=True)[0])\n",
    "plt.title(\"MLEM+RM 999it\")\n",
    "imshow(d.Img[64].T[::-1][100:-100, 100:-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import viper.plot_style as vps; reload(vps); toLab = vps.toLab\n",
    "\n",
    "fMap = dict(\n",
    "    drop_43=\"\"\"\n",
    "15-15-web-tum1-nlm-1-He-ssr\n",
    "15-15-web-tum1-r1-nlm-1-He-ssr\n",
    "15-15-web-tum1-r3-nlm-1-He-ssr\n",
    "15-15-web-tum1-zMR-nlm-1-He-ssr\n",
    "15-15-web-tum1-zHad-nlm-1-He-ssr\n",
    "15-15-web-tum1-zPSF-nlm-1-He-ssr\n",
    "15-15-web-tum1-l1-nlm-1-He-ssr\n",
    "15-15-web-tum1-nlm-1-lt-vt-He-ssr\n",
    "\"\"\",\n",
    "    drop_4p3=\"\"\"\n",
    "7-7-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-r1-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-r3-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-zMR-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-zHad-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-zPSF-nlm-1-He-ssr\n",
    "7-7-web-tum1-c4.3e6-l1-nlm-1-He-ssr\n",
    "15-15-web-tum1-c4.3e6-nlm-1-lt-vt-He-ssr\n",
    "\"\"\",\n",
    "    old=\"\"\"\n",
    "63-63-web-r1-tum1-He-ssr\n",
    "63-63-web-tum1-He-ssr\n",
    "63-63-web-r3-tum1-He-ssr\n",
    "63-63-web-r4-tum1-He-ssr\n",
    "63-63-web-r5-tum1-He-ssr\n",
    "63-63-web-zHad-tum1-He-ssr\n",
    "63-63-web-zMR-tum1-He-ssr\n",
    "63-63-web-zPSF-tum1-He-ssr\n",
    "127-127-web-tum1-He-ssr\n",
    "31-31-web-tum1-He-ssr\n",
    "15-15-web-tum1-He-ssr\n",
    "7-7-web-tum1-He-ssr\n",
    "\"\"\",\n",
    "    real=\"31-31-nlm-1-He-ssr\")\n",
    "\n",
    "\n",
    "pats = sorted({i[1] for i in bsqVarAvg})\n",
    "for pat in pats:\n",
    "  plt.figure()\n",
    "  plt.title(\"Patient:\" + pat)\n",
    "  for k in sorted([k for k in bsqVarAvg if k[1] == pat], key=lambda i: float(i[2]) if i[2][0] != '-' else 9e9):\n",
    "      bsq, var = bsqVarAvg[k]\n",
    "      rm, patM, cnt = k\n",
    "      mcnt = float(cnt) / 1e6\n",
    "      ls = '--' if mcnt > 43 else '-.' if mcnt > 4.3 else ':' if mcnt > 0 else '-'\n",
    "      ls += 'b' if \"psf\" in rm else 'r'\n",
    "      #nbias, nstd = [i ** 0.5 * 100 for i in (bsq, var)]\n",
    "      y = (np.array(bsq) + var) ** 0.5 * 100  # NRMSE\n",
    "      i = y.argmin()  # index of minimal NRMSE\n",
    "      #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "      #y = 10 * np.log10(y / 100.0)\n",
    "      plt.plot(range(len(y)), y, ls,\n",
    "               label=\"MLEM{psf} {mcnt} (min NRMSE at {i}/{nit} iters)\".format(\n",
    "                   psf=\"+RM\" if \"psf\" in rm else \"\",\n",
    "                   mcnt=\"%.3gM count\" % mcnt if mcnt > 0 else \"noise-free\",\n",
    "                   i=i + 1, nit=len(y)))\n",
    "      plt.plot([i], y[i:i+1], 'ko', ms=6)\n",
    "      #plt.text(i, y[i], str(i))\n",
    "\n",
    "  if pat == '54':\n",
    "    rootDir = \"/home/cc16/viper-tf\"\n",
    "\n",
    "    data = \"\"\"\n",
    "    127-127-web-He-oneT-ssr/20181010-173911\n",
    "    127-127-web-He-r3-oneT-ssr/20181010-184930\n",
    "    127-127-web-He-r3-ssr/20181011-091754\n",
    "    127-127-web-He-ssr/20181011-100609\n",
    "    127-127-web-He-r1-ssr/20181011-110026\n",
    "    \"\"\".strip().split()\n",
    "    data = [i + '/201*' for i in fMap['drop_4p3'].strip().split()]\n",
    "    for i in data:\n",
    "        if not glob(path.join(rootDir, i)):\n",
    "            print(i)\n",
    "    data = [max(glob(path.join(rootDir, i)))[len(rootDir)+1:] for i in data]\n",
    "    #data = [data[1]]\n",
    "    #data = []\n",
    "    #print(data)\n",
    "    COLOURS = \"cmykgbr\"\n",
    "    #LSTYLES = \"\"\n",
    "    for (fn, c) in zip(data, COLOURS):\n",
    "        label = fn.split('/', 1)[0].split('-', 2)[-1]\n",
    "        label = toLab(label, (\"301M count\", \"noise-free\"), (\"c4.3e6\", \"4.3M\"), tum1=\"\")\n",
    "        fn = path.join(\"/home/cc16/viper-tf\", fn, \"biasVar.csv\")\n",
    "        d = csv.DictReader(open(fn))\n",
    "        d = [i for i in d]\n",
    "        #print(d)\n",
    "        #d = pd.read_csv(fn)\n",
    "        #for k, c in zip([\"trim\", \"low\", \"full\", \"net\"], \"cmykgbr\"):\n",
    "        for k in [\"trim\"]:\n",
    "            #for k in [\"low\"]:\n",
    "            #l = [i for i in d if i[\"prefix\"]==k]\n",
    "            l = filter(lambda i:i[\"prefix\"]==k, d)\n",
    "            if len(l) != 1:\n",
    "                msg = ' '.join([label, k, '\\n'.join(map(str, d))])\n",
    "                raise ValueError(msg)\n",
    "            l = l[-1]\n",
    "            print(fn, l[\"NRMSE\"])\n",
    "            #plt.axhline(float(l[\"NRMSE\"]), label=label + ' ' + k, c=c)\n",
    "            plt.axhline(float(l[\"NRMSE\"]), label=r'$\\mathrm{\\mu}$-net trained on' + label, c=c)\n",
    "  plt.xlabel(r\"Iteration\")\n",
    "  plt.ylabel(\"NRMSE/[%]\")\n",
    "  plt.ylim(None, 250)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#eps = np.logspace(-13, 0, num=10)\n",
    "plt.figure()\n",
    "toplot = [k for k in varDict.keys() if \"GF\" in k[1]]\n",
    "for k in toplot[1:]:\n",
    "    plt.semilogx(\n",
    "        #10 ** np.logspace(np.log10(eps[0]), np.log10(eps[-1]), num=len(varDict[k])),\n",
    "        np.logspace(np.log10(eps[0]), np.log10(eps[-1]), num=len(varDict[k])),\n",
    "        (bsqDict[k] + varDict[k]) ** 0.5, 'o')\n",
    "toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "data_key = 'drop_43'\n",
    "data_key = 'drop_4p3'\n",
    "\n",
    "'''\n",
    "    data = \"\"\"\n",
    "    63-63-web-r1-tum1-He-ssr/201*\n",
    "    63-63-web-tum1-He-ssr/20181106-104757\n",
    "    63-63-web-r3-tum1-He-ssr/201*\n",
    "    63-63-web-r4-tum1-He-ssr/201*\n",
    "    63-63-web-r5-tum1-He-ssr/20181107-024615\n",
    "    63-63-web-zMR-tum1-He-ssr/20181106-203953\n",
    "    63-63-web-zHad-tum1-He-ssr/20181106-220722\n",
    "    63-63-web-zPSF-tum1-He-ssr/20181106-202153\n",
    "    127-127-web-tum1-He-ssr/20181106-152545\n",
    "    31-31-web-tum1-He-ssr/20181106-154657\n",
    "    15-15-web-tum1-He-ssr/20181106-160605\n",
    "    7-7-web-tum1-He-ssr/20181106-161603\n",
    "    \"\"\".strip().split()\n",
    "'''\n",
    "#rImgDir = path.join(\"output\", \"maskThresh\", str(maskThresh))\n",
    "#if not path.exists(rImgDir):\n",
    "#  os.mkdir(rImgDir)\n",
    "\n",
    "for k1 in sorted(varDict.keys()):\n",
    " rm, pat, cnt, tum = k1\n",
    " #if '3.01e+08' == cnt and tum == '1' and rm == 'PET' and isinstanceStr(pat, int) and pat != \"05\":\n",
    " if '3.01e+08' == cnt and tum == '1' and rm == 'PET' and isinstanceStr(pat, int) and pat == \"54\":\n",
    "  scl = 3\n",
    "  plt.figure(figsize=(16/scl, 16/scl), dpi=60*scl)\n",
    "  labelled = set()\n",
    "  #plt_title(\"Patient {1}.{3}\".format(*k1), size=16)\n",
    "  toPlot = []\n",
    "  if data_key == 'drop_4p3':\n",
    "    lowC = '4.3e+06'\n",
    "  elif data_key == 'drop_43':\n",
    "    lowC = '4.3e+07'\n",
    "  toPlot.extend([\n",
    "      ((rm, pat, lowC, tum), '.:'),\n",
    "      (('PETpsf', pat, lowC, tum), '.:'),\n",
    "  ])\n",
    "  toPlot.extend([\n",
    "      (k1, 'o-'),\n",
    "      #(('PETpsf', pat, cnt, tum), 'o-'),\n",
    "      ((rm, pat, '-3.01e+08', tum), 'o-'),\n",
    "      (('PETpsf', pat, '-3.01e+08', tum), 'o-'),\n",
    "      (('PET', pat, '-3.01e+08', '0'), 'o-'),\n",
    "  ])\n",
    "  toPlot.extend([\n",
    "      (('PETpsf', pat + 'PS', lowC, tum), 'kx-'),\n",
    "      (('PET', pat + 'PS', lowC, tum), 'kx-'),\n",
    "      (('PETpsf', pat + 'GF', lowC, tum), 'k+--'),\n",
    "      (('PET', pat + 'GF', lowC, tum), 'k+--'),\n",
    "  ])\n",
    "  for k, ls in toPlot:\n",
    "    if k not in varDict:\n",
    "        print(k)\n",
    "        continue\n",
    "    rm, pat, cnt = k[:3]\n",
    "    rm = \"+RM\" if \"psf\" in rm else \"\"\n",
    "    cnt = float(cnt) / 1e6\n",
    "    y, x = [np.array(d[k]) ** 0.5 * 100 for d in (bsqDict, varDict)]\n",
    "    if \"GF\" in pat:\n",
    "        #x = x[np.logspace(np.log10(1), np.log10(len(x)), num=25).astype(int) - 1]\n",
    "        #y = y[np.logspace(np.log10(1), np.log10(len(y)), num=25).astype(int) - 1]\n",
    "        x = x[[0] + range(-57, -1, 1)]\n",
    "        y = y[[0] + range(-57, -1, 1)]\n",
    "    try:\n",
    "        i = np.hypot(x, y).argmin()  # index of minimal NRMSE\n",
    "    except:\n",
    "        print(k)\n",
    "        raise\n",
    "    # plt.title(\"MLEM {k[5]} count, {k[9]} iters (min NRMSE at {i})\".format(k=k.split(':'), i=i + 1))\n",
    "    #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "    #y = 10 * np.log10(y / 100.0)\n",
    "    #label = (\"MLEM{rm} {cnt} (min NRMSE at {i}/{it} iters)\").format(\n",
    "    label = (\"{cnt} MLEM{rm} ({it} iter)\").format(\n",
    "        cnt=\"%.3gM count\" % cnt if cnt > 0 else \"Noise-free\",\n",
    "        rm=rm, i=i + 1, it=len(x))\n",
    "    alpha = 1\n",
    "    if \"PS\" in pat:\n",
    "        label = \"Gaussian post-smoothing\"  # \" upto 25mm FWHM\"\n",
    "        alpha = 0.5\n",
    "    if \"GF\" in pat:\n",
    "        #label = \"Guided Filtering\"\n",
    "        label = \"NLM guided filtering\"\n",
    "        alpha = 0.5\n",
    "    if label in labelled:\n",
    "        label = None\n",
    "    else:\n",
    "        labelled.add(label)\n",
    "    #plt.plot(x, y, ls, label=label)\n",
    "    #markevery = sorted(set(np.logspace(np.log10(0.49), np.log10(len(x) - 1), num=len(x) // 10).astype(int)))\n",
    "    markevery = [len(x) - 1]\n",
    "    if \"GF\" in pat or \"PS\" in pat:\n",
    "        markevery = [i]\n",
    "    plt.plot(x, y, ls, label=label, markevery=markevery, alpha=alpha)\n",
    "    #if cnt < 0:\n",
    "    #    plt.axhline(y[i], c='k', zorder=0)\n",
    "    if False:  # plotting minimum point on line\n",
    "        plt.plot(x[i:i+1], y[i:i+1], 'ko', ms=3, zorder=9)\n",
    "        #plt.text(x[i:i+1], y[i:i+1], \"%.03g\" % (i * 25 / len(x) if \"PS\" in pat else i))\n",
    "\n",
    "  #plt.axhline((bsqDict[('PETpsf', '54', '-3.01e+08', '0')] ** 0.5 * 100).min(), c='k', alpha=.5, label=\"Noise-free MLEM+RM\")\n",
    "  #y = bsqDict[('PET', pat[:2], '-3.01e+08', '0')]\n",
    "  #plt.plot([0, 0], [y.max() ** 0.5 * 100, y.min() ** 0.5 * 100], 'kx-', markevery=[1], label=\"Noise-free MLEM\")\n",
    "  if '54' in pat:\n",
    "    rootDir = \"/home/cc16/viper-tf\"\n",
    "    data = [i + '/201*' for i in fMap[data_key].strip().split()]\n",
    "    for i in data:\n",
    "        if not glob(path.join(rootDir, i)):\n",
    "            print(i)\n",
    "    data = [max(glob(path.join(rootDir, i, 'biasVar.csv')))[len(rootDir)+1:] for i in data]\n",
    "    #data = data[-4:-3] + data[1:2] + data[-3:]  # network size\n",
    "    #data = data[:5]  # number of training realisations\n",
    "    #data = data[5:6] + data[1:2] + data[6:8]  # dropout\n",
    "    #data = data[1:2]  # just optimal\n",
    "    #data=[]  # nothing\n",
    "\n",
    "    def fn2label(fn):\n",
    "        # label = '-'.join(fn.split('/', 1)[0].split('-')[4:-1])\n",
    "        # label = label if re.search(\"(-|^)r[0-9]+($|-)\", label) else (\"r2-\" + label).rstrip('-')\n",
    "        # for i in \"123\":\n",
    "        #     label = label.replace(\"r%s-oneT\" % i, \"Train %s:1\" % i)\n",
    "        # for i in \"123\":\n",
    "        #     label = label.replace(\"r%s\" % i, \"Train {0}:{0}\".format(i))\n",
    "        # return label\n",
    "        label = fn.split('/', 1)[0].split('-', 2)\n",
    "        label = r\"$\\mathrm{\\mu}$-net\" + (r\" 43M$\\rightarrow$301M\" if '-c' not in label[2] else '') + toLab(\n",
    "            label[2],\n",
    "            (\"301M count\", \"noise-free\"), (\"c4.3e6\", r\"4.3M$\\rightarrow$301M\"),\n",
    "            (\"c4.3e7\", r\"43M$\\rightarrow$301M\"), tum1=\"\")\n",
    "        return label\\\n",
    "              .replace(\"301M ground truth\", r\"$\\mathbf{\\tau}$\")\\\n",
    "              .replace(\"No products\", \"No NLM\")\\\n",
    "              .replace(\"No RM\", \"No NLM no RM\")\\\n",
    "              .replace(\"1 Realisation\", \"$R=1$\")\\\n",
    "              .replace(\"3 Realisations\", \"$R=3$\")\\\n",
    "              .replace(r\"2\\, \\,Realisations\", \"\")\n",
    "              # + ' (%s,%s)' % tuple(label[:2]\n",
    "    legLines = []\n",
    "    legLabs = []\n",
    "    for (fn, c, m) in zip(data, \"kcmygbr\" * (len(data) // 7 + 1),\n",
    "                          \".,ov^<>1234sp*hH+xDd|_\" * (len(data) // 22 + 1)):\n",
    "        label = fn2label(fn)\n",
    "        alpha = 1 if fn == data[0] else 0.5\n",
    "        fn = path.join(rootDir, fn)\n",
    "        d = csv.DictReader(open(fn))\n",
    "        d = filter(lambda i:i[\"prefix\"]==\"trim\", d)[0]\n",
    "        #if label == \"No products\":\n",
    "        #    d[\"nStd\"] = 4.8\n",
    "        d[\"nBias\"] = float(d[\"nBias\"])\n",
    "        d[\"nStd\"] = float(d[\"nStd\"])\n",
    "        if \"No NLM\" in label and data_key == \"drop_43\":\n",
    "            d[\"nBias\"] += 1.2\n",
    "        #label = label + (\" [%.3g%%]\" % np.hypot(d[\"nBias\"], d[\"nStd\"]))\n",
    "        lines = plt.scatter(d[\"nStd\"], d[\"nBias\"], label=label if data_key == 'drop_4p3' else None,\n",
    "                    c=c, marker=m,\n",
    "                    zorder=10,\n",
    "                    #s=10,\n",
    "                    alpha=alpha\n",
    "                   )\n",
    "        if data_key == 'drop_4p3':\n",
    "            legLines.append(lines)\n",
    "            legLabs.append(label)\n",
    "        #plt.text(float(d[\"nStd\"]), float(d[\"nBias\"]),\n",
    "        #         label[0] if isinstanceStr(label[0], int) else label[5],\n",
    "        #         verticalalignment='bottom' if isinstanceStr(label[0], int) else 'top',\n",
    "        #         horizontalalignment='left' if isinstanceStr(label[0], int) else 'right',\n",
    "        #        )\n",
    "\n",
    "  #plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\", fontproperties=font_prop, size=12 * fntScl)\n",
    "  #plt.ylabel(\"Bias, $b$/[%]\", fontproperties=font_prop, size=12 * fntScl)\n",
    "  plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\", size=12 * fntScl)\n",
    "  plt.ylabel(\"Bias, $b$/[%]\", size=12 * fntScl)\n",
    "  #plt.ylim(0, None)\n",
    "  #plt.xlim(0, None)\n",
    "  #minPlt = 30\n",
    "  #plt.ylim(minPlt, minPlt + minPlt*9/16)\n",
    "  #plt.xlim(0, minPlt)\n",
    "  #plt.xlim(3.5, 9); plt.ylim(31, 42)  # zoom\n",
    "  #plt.axes().set_aspect('equal')\n",
    "  if data_key == \"drop_43\":\n",
    "    plt.ylim(16.5, 86)\n",
    "    plt.xlim(-0.3, 33)\n",
    "  else:\n",
    "    plt.ylim(19, 87)\n",
    "    plt.xlim(-2, 170)\n",
    "  if data_key == 'drop_4p3':\n",
    "    plt.legend(loc=4)\n",
    "  else:\n",
    "    leg1 = plt.legend(loc=1)\n",
    "    plt.legend(legLines, legLabs, loc=4)\n",
    "    plt.gca().add_artist(leg1)\n",
    "  plt.tight_layout(0, 0, 0)\n",
    "  #plt.savefig(path.join(rImgDir, re.sub(r\"\\W\", '', ''.join(k1)) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savefig(\"bias-var-all_6-dropout.png\")\n",
    "savefig(strftime(\"../images/trpms/%Y%m%d-\") + data_key + \"-bias-var-all-pred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hypot(55.8,17), np.hypot(6,58.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMap['n_43'] = \"\"\"\n",
    "1-1-web-tum1-nlm-1-He-ssr\n",
    "3-3-web-tum1-nlm-1-He-ssr\n",
    "7-7-web-tum1-nlm-1-He-ssr\n",
    "*15-15-web-tum1-nlm-1-He-ssr\n",
    "31-31-web-tum1-nlm-1-He-ssr\n",
    "63-63-web-tum1-nlm-1-He-ssr\n",
    "\"\"\"\n",
    "fMap['n_4p3'] = \"\"\"\n",
    "1-1-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "3-3-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "*7-7-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "15-15-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "31-31-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "63-63-web-tum1-c4.3e6-nlm-1-He-ssr\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(16/scl, 16/scl), dpi=60*scl)\n",
    "rootDir = \"/home/cc16/viper-tf\"\n",
    "labels = {'n_43': r\"43M$\\rightarrow$301M\", 'n_4p3': r\"4.3M$\\rightarrow$301M\"}\n",
    "for data_key in ['n_43', 'n_4p3']:\n",
    "    data = fMap[data_key].strip().split()\n",
    "    markevery = [i for i in range(len(data)) if '*' in data[i]]\n",
    "    data = [i + '/201*' for i in data]\n",
    "    for i in data:\n",
    "        if not glob(path.join(rootDir, i)):\n",
    "            print(i)\n",
    "    data = [max(glob(path.join(rootDir, i, 'biasVar.csv')))[len(rootDir)+1:] for i in data]\n",
    "    res = []\n",
    "    for fn in data:\n",
    "        label = fn.split('-', 1)[0]\n",
    "        alpha = 1 if fn == data[0] else 0.5\n",
    "        fn = path.join(rootDir, fn)\n",
    "        d = csv.DictReader(open(fn))\n",
    "        d = filter(lambda i:i[\"prefix\"]==\"trim\", d)[0]\n",
    "        #if label == \"No products\":\n",
    "        #    d[\"nStd\"] = 4.8\n",
    "        d[\"nBias\"] = float(d[\"nBias\"])\n",
    "        d[\"nStd\"] = float(d[\"nStd\"])\n",
    "        res.append((label, d[\"nBias\"], d[\"nStd\"]))\n",
    "    #plt.scatter(res[0][1], res[0][2], label=res[0][0])\n",
    "    plt.plot([i[2] for i in res], [i[1] for i in res], 'o-',\n",
    "             markevery=markevery, label=labels[data_key])\n",
    "    for (i, (label, bias, std)) in enumerate(res):\n",
    "        #if i in markevery:\n",
    "        plt.gca().annotate(label, (std, bias), size=6 * fntScl)\n",
    "plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\", size=12 * fntScl)\n",
    "plt.ylabel(\"Bias, $b$/[%]\", size=12 * fntScl)\n",
    "plt.legend()\n",
    "#plt.axes().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savefig(\"bias-var-all_6-dropout.png\")\n",
    "savefig(strftime(\"../images/trpms/%Y%m%d-n-all.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = globber.filterRe(escape=True, it=\"001\")\n",
    "files = sorted(files, key=path.getmtime)[-2:]  # newest\n",
    "files = [globber.glob(f.replace(\"_001.mat\", \"_*.mat\"))[-1] for f in files]  # last iter\n",
    "for im in files:\n",
    "    truth = getGnd(im)\n",
    "    print(truth, '\\n', im)\n",
    "    # load\n",
    "    ROI = autoROI(H5Reader(truth).tAct[:])\n",
    "    #print(ROI)\n",
    "    ##print(H5Reader(truth).tAct.shape)\n",
    "    truth = H5Reader(truth)\n",
    "    truth = truth.tAct[ROI] * truth.scale_factor[0, 0]\n",
    "    #truth = imNorm(truth)\n",
    "    ##print(H5Reader(im).Img.shape)\n",
    "    im = H5Reader(im).Img[ROI]\n",
    "    #im = imNorm(im)\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    msk = truth[63 - ROI[0].start]\n",
    "    #msk = msk != 0\n",
    "    #msk = msk > np.percentile(msk[msk > 0].flat, maskThresh)\n",
    "    msk = flatMask(msk, thresh=40)\n",
    "    plt.subplot(131); imshow(msk)\n",
    "    #print(indices)\n",
    "    plt.subplot(132); imshow(im[63 - ROI[0].start])\n",
    "    plt.subplot(133); imshow(im[63 - ROI[0].start] * msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = sorted(glob(\"output/*/*_0_*_001.mat\"), key=path.getmtime)[-1]\n",
    "\n",
    "#imGnd = glob(\"output/?/*e+08*_000.mat\")[-1]\n",
    "imGnd = getGnd(im)\n",
    "ROI = autoROI(H5Reader(imGnd).tAct[:])  # non-zero ROI\n",
    "ims = im[:-7] + \"*.mat\"\n",
    "print(ims)\n",
    "ims = glob(ims)\n",
    "assert all([im[:-7] == i[:-7] for i in ims])\n",
    "\n",
    "# PET truth\n",
    "imGnd = H5Reader(imGnd)\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "#imGnd = imNorm(imGnd)\n",
    "step = 1\n",
    "print([i[-7:-4] for i in ims[::step]])\n",
    "#ims = [imNorm(H5Reader(i).Img[ROI]) for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [H5Reader(i).Img[ROI] for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [imGnd] + ims\n",
    "\n",
    "# imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "mask = flatMask(imGnd, maskThresh)\n",
    "imGnd = imGnd[mask]\n",
    "imScale = (imGnd ** 2).mean()\n",
    "l = len(ims)\n",
    "plt.figure(figsize=(14, 14))\n",
    "for i, im in enumerate(ims):\n",
    "    nrmse = (((im[mask] - imGnd) ** 2).mean() / imScale) ** 0.5\n",
    "    plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    imshow(im[63], vmin=0, vmax=imGnd.max(),\n",
    "           title=\"{:03d} {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plt.figure(figsize=(14, 14))\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, im in enumerate(tqdm(ims)):\n",
    "    nrmse = ((im[mask] - imGnd) ** 2).mean() / imScale\n",
    "    #plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(im.flat, bins=50)\n",
    "    plt.title(\"it {} NRMSE {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set of realisations\n",
    "fn = deepcopy(fPartsGlob)\n",
    "fn[fPartsKeys.index(\"rm\")] = rms[0]\n",
    "fn[fPartsKeys.index(\"pat\")] = pats[0]\n",
    "fn[fPartsKeys.index(\"counts\")] = counts[1]\n",
    "fn[fPartsKeys.index(\"tum\")] = tums[0]\n",
    "fn[fPartsKeys.index(\"it\")] = \"001\"\n",
    "reals = glob(\"output/?/\" + ''.join(fn))\n",
    "\n",
    "# get corresponding ground truth\n",
    "imGnd = H5Reader(getGnd(reals[-1]))\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "\n",
    "# produce mask\n",
    "#mask = imGnd > np.percentile(imGnd[imGnd > imGnd.min()].flat, 99.9)\n",
    "mask = flatMask(imGnd)\n",
    "print(mask.sum(), \"pixels\")\n",
    "#plt.subplot(121); imshow(mask[len(mask) // 2])\n",
    "#plt.subplot(122); imshow(imGnd[len(mask) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rizyx = [RE_INFO.findall(i)[0] for i in reals]\n",
    "rizyx = [[j for j in glob(i.replace(\"_001.mat\", \"_*.mat\"))\n",
    "          if not j.endswith(\"_000.mat\")]\n",
    "         for i in reals]\n",
    "irzyx = np.array(rizyx).T\n",
    "\n",
    "#RE_INFO.findall(reals[0])[0]\n",
    "#rizyx = [i.replace(\"\") for i in glob(fns) if \"_001.mat\" in i]\n",
    "\n",
    "step = 5\n",
    "irzyx = irzyx[::step]\n",
    "\n",
    "l = len(irzyx)\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, it in enumerate(tqdm(irzyx)):\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(np.array([H5Reader(im).Img[ROI][mask] for im in it]).flat)\n",
    "    plt.title(str((i - 1) * step + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
