{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from glob import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import re\n",
    "\n",
    "from caspyr.utils import H5Reader\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, regex, glob\n",
    "fParts = (\n",
    "    (\"meta0\", \".*real_\", \"*real_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_nosharp_[0-9]+_AD_\", \"_nosharp_*_AD_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"[-0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))\n",
    "fPartsKeys = [i[0] for i in fParts]\n",
    "fPartsVals = [i[1] for i in fParts]\n",
    "fPartsGlob = [i[2] for i in fParts]\n",
    "RE_INFO = ''.join('(' + i + ')' for i in fPartsVals)\n",
    "RE_INFO = re.compile(RE_INFO)\n",
    "FOLDERS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoROI(im):\n",
    "    \"\"\"return bounding box tuple(slice) of non-zero elements\"\"\"\n",
    "    inds = np.array(im.nonzero())\n",
    "    mins = inds.min(axis=1)\n",
    "    maxs = inds.max(axis=1)\n",
    "    return tuple(slice(i, j) for i, j in zip(mins, maxs))\n",
    "\n",
    "\n",
    "def imNorm(im, assumeZeroMin=True):\n",
    "    \"\"\"in-place, average 1 count/voxel\"\"\"\n",
    "    if not assumeZeroMin:\n",
    "        im -= im.min()\n",
    "    im *= im.size / im.max()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([fn for i in range(FOLDERS) for fn in glob(\"%d/*.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "\n",
    "rms = sorted({i[fPartsKeys.index(\"rm\")] for i in parts})\n",
    "pats = sorted({i[fPartsKeys.index(\"pat\")] for i in parts}, key=int)\n",
    "counts = sorted({i[fPartsKeys.index(\"counts\")] for i in parts}, key=float)\n",
    "tums = sorted({i[fPartsKeys.index(\"tum\")] for i in parts}, key=int)\n",
    "its = sorted({i[fPartsKeys.index(\"it\")] for i in parts}, key=int)\n",
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#varDict = {}\n",
    "#bsqDict = {}\n",
    "with open(\"biasVar.pkl\") as fd:\n",
    "    bsqDict, varDict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "fn = deepcopy(fPartsGlob)\n",
    "for rm in tqdm(rms, desc=\"RM\"):\n",
    "    fn[fPartsKeys.index(\"rm\")] = rm\n",
    "    for pat in tqdm(pats, desc=\"Patient\"):\n",
    "        fn[fPartsKeys.index(\"pat\")] = pat\n",
    "        for cnt in tqdm(counts, desc=\"Counts\"):\n",
    "            fn[fPartsKeys.index(\"counts\")] = cnt\n",
    "            for tum in tqdm(tums, desc=\"Tumours\"):\n",
    "                fn[fPartsKeys.index(\"tum\")] = tum\n",
    "                files = sorted(glob(\"[%s]/%s\" % (''.join(map(str, range(FOLDERS))), ''.join(fn))))\n",
    "                if not files:\n",
    "                    continue\n",
    "                #print(len(files))\n",
    "                #print('\\n'.join(files))\n",
    "                parts = [RE_INFO.findall(i)[0] for i in files]\n",
    "                #print(len(parts))\n",
    "                parts = sorted({i[:-2] + (\"\",) + i[-1:] for i in parts})  # ignore iteration\n",
    "                parts = [list(p) for p in parts]\n",
    "                #print('\\n'.join(':'.join(i) for i in parts))\n",
    "                # per-iteration results vectors\n",
    "                bsq = []\n",
    "                var = []\n",
    "                # ground truth image\n",
    "                p = deepcopy(parts[0])  # first realisation\n",
    "                p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "                p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "                p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "                p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "                p = ''.join(p)\n",
    "                if not glob(p):\n",
    "                    raise IOError(\"Could not find \" + p)\n",
    "                if False:  # TEST\n",
    "                    imGnd = imNorm(H5Reader(glob(p)[0]).tAct[ROI])\n",
    "                    tmp = [(imGnd == imNorm(H5Reader(i).tAct[ROI])).all() for i in glob(p)]\n",
    "                    print(len(tmp), glob(p))\n",
    "                    assert all(tmp)\n",
    "                    continue\n",
    "                p = glob(p)[0]\n",
    "                ROI = autoROI(H5Reader(p).tAct[:])  # non-zero ROI\n",
    "                imGnd = imNorm(H5Reader(p).tAct[ROI])  # PET truth\n",
    "                mask = imGnd != 0\n",
    "                imGnd = imGnd[mask]\n",
    "                imScale = (imGnd ** 2).mean()\n",
    "                # pre-allocate one set of realisations [R, X, Y, Z]\n",
    "                #ims = np.zeros((len(parts),) + imGnd.shape, dtype=imGnd.dtype)\n",
    "                ims = np.zeros((len(parts), imGnd.size), dtype=imGnd.dtype)\n",
    "                with trange(1, 1 + (300 if \"psf\" in rm else 100),\n",
    "                                 desc=\"%d reals iter\" % len(parts)) as tIters:\n",
    "                  for it in tIters:\n",
    "                    for i, p in enumerate(tqdm(parts, desc=\"realisations\", disable=True)):\n",
    "                        p[-2] = \"%03d\" % it\n",
    "                        ims[i] = imNorm(H5Reader(''.join(p)).Img[ROI])[mask]\n",
    "                    imMean = ims.mean(axis=0)\n",
    "                    #bsq.append(((imMean - imGnd) / imGnd).mean())\n",
    "                    #var.append((np.std(ims, axis=0, ddof=1) / imMean).mean())\n",
    "                    bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                    var.append((np.var(ims, axis=0, ddof=1)).mean() / imScale)\n",
    "                    tIters.set_postfix(\n",
    "                        # N.B: mseTest will be nonzero due to var(..., ddof=1)\n",
    "                        # mseTest = ((ims - imGnd) ** 2).mean() / imScale - bsq[-1] - var[-1],\n",
    "                        mse=bsq[-1] + var[-1], bsq=bsq[-1], var=var[-1], refresh=False)\n",
    "                bsqDict[':'.join(parts[0])] = bsq\n",
    "                varDict[':'.join(parts[0])] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    with open(\"biasVar.pkl\", \"w\") as fd:\n",
    "        pickle.dump((bsqDict, varDict), fd, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(varDict.keys()))\n",
    "rmPatCnt = []\n",
    "for i1, i3, i5 in {(i[1], i[3], i[5]) for k in sorted(varDict.keys()) for i in [k.split(\":\")]}:\n",
    "    avgBiasVar = [\n",
    "        np.array([src[k] for k in src for i in [k.split(':')] if i[1]==i1 and i[3]==i3 and i[5]==i5]).mean(axis=0)\n",
    "        for src in (bsqDict, varDict)]\n",
    "    rmPatCnt.append((i1, i3, i5, avgBiasVar))\n",
    "    #rmPatCnt.setdefault(i1, {}).setdefault(i3, {})[float(i5)] = res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = sorted({i[1] for i in rmPatCnt})\n",
    "for pat in pats:\n",
    "  plt.figure()\n",
    "  plt.title(\"Train\" if pat == \"1\" else \"Validation\")\n",
    "  for rm, patM, cnt, (bsq, var) in rmPatCnt:\n",
    "    mcnt = float(cnt) / 1e6\n",
    "    if patM == pat:\n",
    "      #ls = '+' if \"psf\" in rm else 'x'\n",
    "      ls = ':' if mcnt <= 43 else '-'\n",
    "      y, x = [i ** 0.5 * 100 for i in (bsq, var)]\n",
    "      #y = x  # std\n",
    "      y = np.hypot(y, x)  # NRMSE\n",
    "      i = y.argmin()  # index of minimal NRMSE\n",
    "      #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "      #y = 10 * np.log10(y / 100.0)\n",
    "      plt.plot(range(len(x)), y, ls,\n",
    "               label=\"MLEM{psf} {mcnt:.0f}M count (min NRMSE at {i}/{nit} iters)\".format(\n",
    "                   psf=\"+RM\" if \"psf\" in rm else \"\", mcnt=mcnt, i=i + 1, nit=len(y)))\n",
    "      plt.plot([i], y[i:i+1], 'ko', ms=6)\n",
    "  plt.xlabel(r\"Iteration\")\n",
    "  plt.ylabel(\"NRMSE/[%]\")\n",
    "  plt.ylim(0, 200)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in sorted(varDict.keys(), key=lambda x: x.split(':')):\n",
    " if ':3.01e+08:' in k1:\n",
    "  plt.figure()\n",
    "  plt.title(k1)\n",
    "  for k, ls in zip([k1, k1.replace(':3.01e+08:', ':4.3e+07:')], ['x-', 'o-']):\n",
    "    y, x = [np.array(d[k]) ** 0.5 * 100 for d in (bsqDict, varDict)]\n",
    "    i = (x + y).argmin()  # index of minimal NRMSE\n",
    "    # plt.title(\"MLEM {k[5]} count, {k[9]} iters (min NRMSE at {i})\".format(k=k.split(':'), i=i + 1))\n",
    "    #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "    #y = 10 * np.log10(y / 100.0)\n",
    "    meta = k.split(':')\n",
    "    meta[1] = \"+RM\" if meta[1][3:] else \"\"\n",
    "    meta[5] = float(meta[5]) / 1e6\n",
    "    plt.plot(x, y, ls, label=\"MLEM{k[1]} {k[5]:.0f}M count (min NRMSE at {i}/{k[9]} iters)\".format(\n",
    "        k=meta, i=i + 1))\n",
    "    plt.plot(x[i:i+1], y[i:i+1], 'ro', ms=6)\n",
    "  plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "  plt.ylabel(\"Bias/[%]\")\n",
    "  plt.ylim(0, None)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in varDict.keys()], key=lambda x: x.split(':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PET_10 = [[r1i1, ..., r1i100], ..., [rNi1, ..., rNi100]]\n",
    "#PETpsf_10 = ...\n",
    "#PET_70 = ...\n",
    "#PETpsf_70 = ...\n",
    "PET_10 = None\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "files = sorted([fn for i in range(FOLDERS) for fn in glob(\"%d/*_300.mat\" % i) + glob(\"%d/*_PET_*_100.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "print(len(parts))\n",
    "for p in tqdm(parts[:1]):\n",
    "    p = list(p)\n",
    "    im = ''.join(p)\n",
    "    p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "    p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "    p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "    p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "    truth = ''.join(p)\n",
    "    truth = glob(truth)[0]\n",
    "    print(truth, im)\n",
    "    # load\n",
    "    ROI = autoROI(H5Reader(truth).tAct[:])\n",
    "    print(ROI)\n",
    "    ##print(H5Reader(truth).tAct.shape)\n",
    "    truth = imNorm(H5Reader(truth).tAct[ROI])\n",
    "    ##print(H5Reader(im).Img.shape)\n",
    "    im = imNorm(H5Reader(im).Img[ROI])\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    plt.subplot(121); plt.imshow(truth[63 - ROI[0].start] != 0)\n",
    "    #print(indices)\n",
    "    plt.subplot(122); plt.imshow(im[63 - ROI[0].start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files[299])\n",
    "print(files[300])\n",
    "im = H5Reader(files[299]).Img[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[ROI][63,].T origin=\"lower\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
