{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import re\n",
    "from os import path\n",
    "import csv\n",
    "#from viper.constants import SIGMA2FWHM_MMR\n",
    "SIGMA2FWHM_MMR = (8 * np.log(2)) ** .5 * 2.08626\n",
    "from scipy.ndimage.filters import gaussian_filter as gauss\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.simplefilter(\"ignore\", category=TqdmExperimentalWarning)\n",
    "    from tqdm.auto import tqdm, trange\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"numpy.dtype size changed\", module=\"h5py\")\n",
    "from caspyr.utils import H5Reader, Globber, glob\n",
    "\n",
    "from viper.plot_style import toLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, cmap=\"Greys\", origin=\"lower\", title=None, **kwargs):\n",
    "    ax = plt.imshow(im, cmap=cmap, origin=origin, **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "def autoROI(im):\n",
    "    \"\"\"return bounding box tuple(slice) of non-zero elements\"\"\"\n",
    "    inds = np.array(im.nonzero())\n",
    "    mins = inds.min(axis=1)\n",
    "    maxs = inds.max(axis=1)\n",
    "    return tuple(slice(i, j) for i, j in zip(mins, maxs))\n",
    "\n",
    "def imNorm(im, assumeZeroMin=True):\n",
    "    \"\"\"in-place, average 1 count/voxel\"\"\"\n",
    "    if not assumeZeroMin:\n",
    "        im -= im.min()\n",
    "    im *= im.size / im.max()\n",
    "    return im\n",
    "\n",
    "def flatMask(im, thresh=50, hw=1):\n",
    "    \"\"\"\n",
    "    thresh  : int, percentile\n",
    "    hw  : int, half width\n",
    "    \"\"\"\n",
    "    from scipy.signal import convolve\n",
    "    m = np.ones([2*hw+1] * im.ndim) * -1\n",
    "    m[hw, hw] = m.size - 1\n",
    "    edges = np.abs(convolve(im, m, mode='same'))\n",
    "    msk = edges < np.percentile(edges.flat, thresh)  # high pass\n",
    "    msk *= im > np.percentile(im[im > 0].flat, 100 - thresh)  # low pass\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globber = Globber(\n",
    "    (\"meta0\", \"output/[0-9]+/brainweb_\", \"output/*/brainweb_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_[0-9]+_subject_\", \"_*_subject_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta6\", \"-S_\", \"-S_\"),\n",
    "    (\"sigma\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta7\", \"-NP_\", \"-NP_\"),\n",
    "    (\"fsPET\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta8\", \"-NT1_\", \"-NT1_\"),\n",
    "    (\"fsT1\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"-?[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"-?[0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskThresh = 50\n",
    "PAD = 3\n",
    "ROI_BW = [(33, 93), (115, 230), (115, 230)]  # zxy\n",
    "ROI_BW = tuple(slice(i + PAD, j - PAD) for (i, j) in ROI_BW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGnd(fn, debug=False):\n",
    "    # ground truth image\n",
    "    counts = globber.split(fn)[globber[\"counts\"]]\\\n",
    "        .replace('-', \"-?\").replace('+', '\\\\+').replace('.', '\\\\.')\n",
    "    files = globber.filterReUnlike(fn, it=\"000\") or globber.filterReUnlike(\n",
    "        fn, meta0=None, meta1=None, rm=None, it=\"000\", counts=counts)  # counts=None\n",
    "    if not files:\n",
    "        raise IOError(\"Could not find truth for:%s\" % fn)\n",
    "    if debug:\n",
    "        #ROI = autoROI(H5Reader(files[0]).tAct[:])  # non-zero ROI\n",
    "        ROI = ROI_BW\n",
    "        imGnd = H5Reader(files[0]).tAct[ROI]\n",
    "        tmp = [(imGnd == H5Reader(i).tAct[ROI]).all() for i in tqdm(files, desc=\"debug\")]\n",
    "        #print(len(tmp), files)\n",
    "        if not all(tmp):\n",
    "            raise ValueError(\"mismatched ground truths:\" + p)\n",
    "    return files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globber.partsVals[:-2] + ['000 -> 300', globber.partsVals[-1]]\n",
    "rms = globber.partsVals[globber[\"rm\"]]\n",
    "pats = globber.partsVals[globber[\"pat\"]]  # int\n",
    "counts = globber.partsVals[globber[\"counts\"]]  # float\n",
    "tums = globber.partsVals[globber[\"tum\"]]  # int\n",
    "its = globber.partsVals[globber[\"it\"]]  # int\n",
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = \"\"\"\n",
    "54\n",
    "\"\"\".strip().split()\n",
    "counts = [\"%.3g\" % (i * 1e6) for i in [43, 301]]\n",
    "tums=['1']\n",
    "#brainweb_PET_*_54-*_4.3*_t1_001.mat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#counts = filter(lambda s: s.startswith('-'), counts)\n",
    "tums=['0']; rms=[\"PETpsf\"]; counts=['4.3e+07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varDict = {}\n",
    "bsqDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputPkl = \"output/biasVar.pkl\"\n",
    "#outputPkl = \"output/biasVar-flat.pkl\"\n",
    "outputPkl = \"output/biasVar-brainweb.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputPkl) as fd:\n",
    "    bsqDict, varDict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "for rm in tqdm(rms, desc=\"RM\"):\n",
    "    for pat in tqdm(pats, desc=\"Patient\"):\n",
    "        for cnt in tqdm(counts, desc=\"Counts\"):\n",
    "            for tum in tqdm(tums, desc=\"Tumours\"):\n",
    "                files = globber.filterRe(\n",
    "                    escape=True,\n",
    "                    rm=rm, pat=pat, counts=cnt, tum=tum,\n",
    "                    it=\"001\")\n",
    "                if not files:\n",
    "                    print(\"cannot find globber files\", rm, pat, cnt, tum)\n",
    "                    continue\n",
    "\n",
    "                # per-iteration results vectors\n",
    "                bsq = []\n",
    "                var = []\n",
    "                # ground truth image`\n",
    "                imGnd = H5Reader(getGnd(files[0]))\n",
    "                #ROI = autoROI(imGnd.tAct[:])  # non-zero ROI\n",
    "                ROI = ROI_BW\n",
    "                imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "                #imGnd = imNorm(imGnd)\n",
    "                # imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "                ####mask = flatMask(imGnd, maskThresh)\n",
    "                mask = imGnd > 0\n",
    "                imGnd = imGnd[mask]\n",
    "                imScale = (imGnd ** 2).mean()\n",
    "                # pre-allocate one set of realisations [R, X, Y, Z]\n",
    "                #ims = np.zeros((len(parts),) + imGnd.shape, dtype=imGnd.dtype)\n",
    "                #ims = np.zeros((len(files), imGnd.size), dtype=imGnd.dtype)\n",
    "                with tqdm(total=len(its),\n",
    "                          desc=\"%d reals, %.3g scale\" % (len(files), imGnd.sum())) as tIters:\n",
    "                  it = 1\n",
    "                  while True:\n",
    "                    usedfiles = filter(path.exists, [p[:-7] + \"%03d.mat\" % it for p in files])\n",
    "                    if not usedfiles:\n",
    "                        if it > 1:\n",
    "                            usedfiles = filter(path.exists, [p[:-7] + \"%03d.mat\" % (it - 1) for p in files])\n",
    "                            last_it_ims = [H5Reader(p).Img[ROI] for p in usedfiles]\n",
    "                        break\n",
    "                    #if len(ims) != len(usedfiles):\n",
    "                    #    log.warn(\"altering preallocation\")\n",
    "                    #    ims = np.zeros((len(usedfiles), imGnd.size), dtype=imGnd.dtype)\n",
    "                    #for i, p in enumerate(tqdm(usedfiles, desc=\"realisations\", disable=True)):\n",
    "                    #    #ims[i] = imNorm(H5Reader(''.join(p)).Img[ROI])[mask]\n",
    "                    #    ims[i] = H5Reader(p).Img[ROI][mask]\n",
    "                    HACK_SKIP = False\n",
    "                    if not HACK_SKIP:\n",
    "                        last_it_ims = [H5Reader(p).Img[ROI] for p in usedfiles]\n",
    "                        ims = [i[mask] for i in last_it_ims]\n",
    "                        imMean = np.mean(ims, axis=0)\n",
    "                        #imMean = ims.mean(axis=0)\n",
    "                        #bsq.append(((imMean - imGnd) / imGnd).mean())\n",
    "                        #var.append((np.std(ims, axis=0, ddof=1) / imMean).mean())\n",
    "                        bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                        #var.append((np.var(ims, axis=0, ddof=min(1, len(ims)-1))).mean() / imScale)\n",
    "                        var.append((np.var(ims, axis=0)).mean() / imScale)\n",
    "                        tIters.set_postfix(\n",
    "                            # N.B: mseTest will be nonzero due to var(..., ddof=1)\n",
    "                            # mseTest = ((ims - imGnd) ** 2).mean() / imScale - bsq[-1] - var[-1],\n",
    "                            mse=bsq[-1] + var[-1], bsq=bsq[-1], var=var[-1], refresh=False)\n",
    "                    tIters.update()\n",
    "                    it += 1\n",
    "                \"\"\"usedfiles = filter(path.exists, [p[:-7] + \"%03d.mat\" % 300 for p in files])\n",
    "                bsq = range(300)\n",
    "                ims = [H5Reader(p).Img[ROI][mask] for p in usedfiles]\"\"\"\n",
    "                #key = list(globber.valRe.findall(files[0])[0])\n",
    "                #key[globber[\"it\"]] = \"\"\n",
    "                #key = ':'.join(key)\n",
    "                #key = ':'.join((rm, pat, cnt, tum))\n",
    "                key = rm, pat, cnt, tum\n",
    "                if not HACK_SKIP:\n",
    "                    bsqDict[key] = np.array(bsq)\n",
    "                    varDict[key] = np.array(var)\n",
    "                # post-smoothing\n",
    "                if 0 < float(cnt) < 301e6:  # and \"psf\" in rm:\n",
    "                    num = it - 1  # len(bsq)\n",
    "                    last_it_ims = np.array(last_it_ims)\n",
    "                    bsq = []\n",
    "                    var = []\n",
    "                    for s in tqdm(np.linspace(0, 25, num=num) / SIGMA2FWHM_MMR, desc=\"PS\"):\n",
    "                        ims = [gauss(im, s)[mask] for im in last_it_ims]\n",
    "                        #if np.all(last_it_ims == ims):\n",
    "                        #    print(s)\n",
    "                        imMean = np.mean(ims, axis=0)\n",
    "                        bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                        #var.append((np.var(ims, axis=0, ddof=min(1, len(ims)-1))).mean() / imScale)\n",
    "                        var.append((np.var(ims, axis=0)).mean() / imScale)\n",
    "                    key = key[0], key[1] + \"PS\", key[2], key[3]\n",
    "                    bsqDict[key] = np.array(bsq)\n",
    "                    varDict[key] = np.array(var)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(outputPkl, \"w\") as fd:\n",
    "    pickle.dump((bsqDict, varDict), fd, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(varDict.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rmPatCnt = []  # average across tumours\n",
    "for rm, pat, cnt in {i[:3] for i in varDict.keys()}:\n",
    "    avgBiasVar = [\n",
    "        np.array([src[k] for k in src if k[:3]==(rm, pat, cnt)]).mean(axis=0)\n",
    "        for src in (bsqDict, varDict)]\n",
    "    rmPatCnt.append((rm, pat, cnt, avgBiasVar))\n",
    "    #rmPatCnt.setdefault(i1, {}).setdefault(i3, {})[float(i5)] = res.mean(axis=0)\n",
    "rmPatCnt.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsqVarAvg = {}  # average across tumours\n",
    "for rm, pat, cnt in {i[:3] for i in varDict.keys() if \"PS\" not in i[1]}:\n",
    "    # dimensions: bias|var, realisation, iteration\n",
    "    avgBiasVar = [\n",
    "        [src[k] for k in src if k[:3]==(rm, pat, cnt)]\n",
    "        for src in (bsqDict, varDict)]\n",
    "    nitMax = max([len(i) for i in avgBiasVar[0]])\n",
    "    avgBiasVar = np.array([[np.pad(i, (0, nitMax-len(i)), 'constant') for i in src]\n",
    "                           for src in avgBiasVar])\n",
    "    # slightly risky as `0` may not signify padding:\n",
    "    nitScale = avgBiasVar.astype(np.bool).astype('i4').sum(axis=1)\n",
    "    nitScale[nitScale==0] = 1\n",
    "    avgBiasVar = avgBiasVar.sum(axis=1) / nitScale\n",
    "    bsqVarAvg[(rm, pat, cnt)] = avgBiasVar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# noise-free debug\n",
    "plt.figure()\n",
    "y = bsqDict[('PET', '04', '-3.01e+08', '0')]\n",
    "plt.plot(y ** 0.5 * 100, label=\"MLEM\")\n",
    "i = y.argmin()\n",
    "plt.scatter([i], [y[i] ** 0.5 * 100])\n",
    "plt.plot(bsqDict[('PETpsf', '04', '-3.01e+08', '0')] ** 0.5 * 100, label=\"PSF\")\n",
    "plt.xlabel(r\"Iteration\")\n",
    "plt.ylabel(\"NRMSE/[%]\")\n",
    "plt.ylim(None, 46)\n",
    "plt.xlim(0, None)\n",
    "plt.legend()\n",
    "\n",
    "_, axs = plt.subplots(1, 2)\n",
    "axs = axs.flat\n",
    "plt.sca(axs[0])\n",
    "d = H5Reader(globber.filterRe(counts=\"-3.01e+08\", it=\"%03d\" % i, rm=\"PET\", escape=True)[0])\n",
    "plt.title(\"MLEM %dit\" % i)\n",
    "imshow(d.Img[64].T[::-1][100:-100, 100:-100])\n",
    "plt.sca(axs[1])\n",
    "d = H5Reader(globber.filterRe(counts=\"-3.01e+08\", it=\"999\", rm=\"PETpsf\", escape=True)[0])\n",
    "plt.title(\"MLEM+RM 999it\")\n",
    "imshow(d.Img[64].T[::-1][100:-100, 100:-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import viper.plot_style as vps; reload(vps); toLab = vps.toLab\n",
    "#from viper.utils.stats import movingAvg, nrmse, biasStd, biasStdMask\n",
    "import viper.utils.stats as vus; reload(vus); nrmse=vus.nrmse; biasStd = vus.biasStd  # , biasStdMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = sorted({i[1] for i in bsqVarAvg})\n",
    "for pat in pats:\n",
    "  plt.figure()\n",
    "  plt.title(\"Patient:\" + pat)\n",
    "  for k in [k for k in bsqVarAvg if k[1] == pat]:\n",
    "      bsq, var = bsqVarAvg[k]\n",
    "      rm, patM, cnt = k\n",
    "      mcnt = float(cnt) / 1e6\n",
    "      ls = '--' if mcnt > 43 else ':' if mcnt > 0 else '-'\n",
    "      ls += 'b' if \"psf\" in rm else 'r'\n",
    "      #nbias, nstd = [i ** 0.5 * 100 for i in (bsq, var)]\n",
    "      y = (np.array(bsq) + var) ** 0.5 * 100  # NRMSE\n",
    "      i = y.argmin()  # index of minimal NRMSE\n",
    "      #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "      #y = 10 * np.log10(y / 100.0)\n",
    "      plt.plot(range(len(y)), y, ls,\n",
    "               label=\"MLEM{psf} {mcnt:.0f}M count (min NRMSE at {i}/{nit} iters)\".format(\n",
    "                   psf=\"+RM\" if \"psf\" in rm else \"\", mcnt=mcnt, i=i + 1, nit=len(y)))\n",
    "      plt.plot([i], y[i:i+1], 'ko', ms=6)\n",
    "      #plt.text(i, y[i], str(i))\n",
    "\n",
    "  if pat == '54':\n",
    "    SIGMA2FWHM_MMR\n",
    "    \"\"\"\n",
    "    127-127-web-He-oneT-ssr/20181010-173911\n",
    "    127-127-web-He-r3-oneT-ssr/20181010-184930\n",
    "    127-127-web-He-r3-ssr/20181011-091754\n",
    "    127-127-web-He-ssr/20181011-100609\n",
    "    127-127-web-He-r1-ssr/20181011-110026\n",
    "    \"\"\"\n",
    "    data = \"\"\"\n",
    "    63-63-web-r1-tum1-He-ssr/20181106-204916\n",
    "    63-63-web-tum1-He-ssr/20181106-104757\n",
    "    63-63-web-r3-tum1-He-ssr/20181106-205550\n",
    "    63-63-web-zHad-tum1-He-ssr/20181106-220722\n",
    "    63-63-web-zMR-tum1-He-ssr/20181106-203953\n",
    "    63-63-web-zPSF-tum1-He-ssr/20181106-202153\n",
    "    \"\"\".strip().split()\n",
    "    data = [data[1]]\n",
    "    #data = []\n",
    "    COLOURS = \"cmykgbr\"\n",
    "    #LSTYLES = \"\"\n",
    "    for (fn, c) in zip(data, COLOURS):\n",
    "        label = fn.split('/', 1)[0].split('-', 2)[-1]\n",
    "        label = toLab(label, tum1=\"\")\n",
    "        fn = path.join(\"/home/cc16/viper-tf\", fn, \"biasVar.csv\")\n",
    "        d = csv.DictReader(open(fn))\n",
    "        d = [i for i in d]\n",
    "        # for k, c in zip([\"trim\", \"low\", \"full\", \"net\"], \"cmykgbr\"):\n",
    "        for k in [\"trim\"]:\n",
    "            l = [i for i in d if i[\"prefix\"]==k]\n",
    "            if len(l) != 1:\n",
    "                msg = ' '.join([label, k, '\\n'.join(map(str, d))])\n",
    "                raise ValueError(msg)\n",
    "            #plt.axhline(float(l[-1][\"NRMSE\"]), label=label + ' ' + k, c=c)\n",
    "            plt.axhline(float(l[-1][\"NRMSE\"]), label=r'$\\mu$Net trained on ' + label, c=c)\n",
    "  plt.xlabel(r\"Iteration\")\n",
    "  plt.ylabel(\"NRMSE/[%]\")\n",
    "  plt.ylim(None, 46)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "rImgDir = path.join(\"output\", \"maskThresh\", str(maskThresh))\n",
    "if not path.exists(rImgDir):\n",
    "  os.mkdir(rImgDir)\n",
    "\n",
    "for k1 in sorted(varDict.keys()):\n",
    " rm, pat, cnt, tum = k1\n",
    " if '3.01e+08' == cnt and tum == '1' and rm == 'PET' and \"PS\" not in pat and pat != \"05\":\n",
    "  plt.figure(figsize=(16/2, 9/2), dpi=60*2)\n",
    "  plt.title(\"Patient {1}.{3}\".format(*k1))\n",
    "  for k, ls in zip([k1,\n",
    "                    (rm, pat, '4.3e+07', tum),\n",
    "                    #('PETpsf', pat, cnt, tum),\n",
    "                    ('PETpsf', pat, '4.3e+07', tum),\n",
    "                    (rm, pat, '-3.01e+08', tum),\n",
    "                    ('PETpsf', pat, '-3.01e+08', tum),\n",
    "                    ('PET', pat + 'PS', '4.3e+07', tum),\n",
    "                    ('PETpsf', pat + 'PS', '4.3e+07', tum),\n",
    "                   ],\n",
    "                   ['o-',\n",
    "                    '.-',\n",
    "                    #'o-',\n",
    "                    '.-', 'o-', 'o-', 'k-', 'k-']):\n",
    "    if k not in varDict:\n",
    "        print(k)\n",
    "        continue\n",
    "    y, x = [np.array(d[k]) ** 0.5 * 100 for d in (bsqDict, varDict)]\n",
    "    try:\n",
    "        i = np.hypot(x, y).argmin()  # index of minimal NRMSE\n",
    "    except:\n",
    "        print(k)\n",
    "        raise\n",
    "    # plt.title(\"MLEM {k[5]} count, {k[9]} iters (min NRMSE at {i})\".format(k=k.split(':'), i=i + 1))\n",
    "    #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "    #y = 10 * np.log10(y / 100.0)\n",
    "    rm, pat, cnt = k[:3]\n",
    "    rm = \"+RM\" if \"psf\" in rm else \"\"\n",
    "    cnt = float(cnt) / 1e6\n",
    "    #label = (\"MLEM{rm} {cnt} (min NRMSE at {i}/{it} iters)\").format(\n",
    "    label = (\"{cnt} MLEM{rm}\").format(\n",
    "        cnt=\"%.0fM count\" % cnt if cnt > 0 else \"noise-free\",\n",
    "        rm=rm, i=i + 1, it=len(x))\n",
    "    if \"PS\" in pat:\n",
    "        label = \"Gaussian post-smoothing\"  # \" upto 25mm FWHM\"\n",
    "        if rm == \"+RM\":\n",
    "            label = None\n",
    "    #plt.plot(x, y, ls, label=label)\n",
    "    markevery = sorted(set(np.logspace(np.log10(0.49), np.log10(len(x) - 1), num=len(x) // 10).astype(int)))\n",
    "    plt.plot(x, y, ls, label=label, markevery=markevery)\n",
    "    if cnt < 0:\n",
    "        plt.axhline(y[i], c='k', zorder=0)\n",
    "    plt.plot(x[i:i+1], y[i:i+1], 'ko', ms=3, zorder=9)\n",
    "    #plt.text(x[i:i+1], y[i:i+1], \"%.03g\" % (i * 25 / len(x) if \"PS\" in pat else i))\n",
    "\n",
    "  if '54' in pat:\n",
    "    data = \"\"\"\n",
    "    63-63-web-r1-tum1-He-ssr/20181106-204916\n",
    "    63-63-web-tum1-He-ssr/20181106-104757\n",
    "    63-63-web-r3-tum1-He-ssr/20181106-205550\n",
    "    63-63-web-r4-tum1-He-ssr/20181107-012338\n",
    "    63-63-web-r5-tum1-He-ssr/20181107-024615\n",
    "    63-63-web-zHad-tum1-He-ssr/20181106-220722\n",
    "    63-63-web-zMR-tum1-He-ssr/20181106-203953\n",
    "    63-63-web-zPSF-tum1-He-ssr/20181106-202153\n",
    "    127-127-web-tum1-He-ssr/20181106-152545\n",
    "    31-31-web-tum1-He-ssr/20181106-154657\n",
    "    15-15-web-tum1-He-ssr/20181106-160605\n",
    "    7-7-web-tum1-He-ssr/20181106-161603\n",
    "    \"\"\".strip().split()\n",
    "    #data = data[1:2] + data[-4:]\n",
    "    data = data[:5]\n",
    "\n",
    "    def fn2label(fn):\n",
    "        # label = '-'.join(fn.split('/', 1)[0].split('-')[4:-1])\n",
    "        # label = label if re.search(\"(-|^)r[0-9]+($|-)\", label) else (\"r2-\" + label).rstrip('-')\n",
    "        # for i in \"123\":\n",
    "        #     label = label.replace(\"r%s-oneT\" % i, \"Train %s:1\" % i)\n",
    "        # for i in \"123\":\n",
    "        #     label = label.replace(\"r%s\" % i, \"Train {0}:{0}\".format(i))\n",
    "        # return label\n",
    "        label = fn.split('/', 1)[0].split('-')\n",
    "        return toLab('-'.join(label[2:]), tum1=\"\") + ' (%s,%s)' % tuple(label[:2])\n",
    "\n",
    "    for (fn, c) in zip(data, \"cmykgbr\" * (len(data) // 7 + 1)):\n",
    "        label = fn2label(fn)\n",
    "        fn = path.join(\"/home/cc16/viper-tf\", fn, \"biasVar.csv\")\n",
    "        d = csv.DictReader(open(fn))\n",
    "        d = [i for i in d if i[\"prefix\"]==\"maskScaled\"][0]\n",
    "        plt.scatter(float(d[\"nStd\"]), float(d[\"nBias\"]), label=label,\n",
    "                    c=c, marker='x' if '-oneT' in fn else '*' if \"\\\\bf\" in label else '+',\n",
    "                    zorder=10,\n",
    "                    #s=100\n",
    "                   )\n",
    "\n",
    "  plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "  plt.ylabel(\"Bias/[%]\")\n",
    "  #plt.ylim(0, None)\n",
    "  plt.xlim(0, None)\n",
    "  #plt.axes().set_aspect('equal')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.savefig(path.join(rImgDir, re.sub(r\"\\W\", '', ''.join(k1)) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = globber.filterRe(escape=True, it=\"001\")\n",
    "files = sorted(files, key=path.getmtime)[-2:]  # newest\n",
    "files = [globber.glob(f.replace(\"_001.mat\", \"_*.mat\"))[-1] for f in files]  # last iter\n",
    "for im in files:\n",
    "    truth = getGnd(im)\n",
    "    print(truth, '\\n', im)\n",
    "    # load\n",
    "    ROI = autoROI(H5Reader(truth).tAct[:])\n",
    "    #print(ROI)\n",
    "    ##print(H5Reader(truth).tAct.shape)\n",
    "    truth = H5Reader(truth)\n",
    "    truth = truth.tAct[ROI] * truth.scale_factor[0, 0]\n",
    "    #truth = imNorm(truth)\n",
    "    ##print(H5Reader(im).Img.shape)\n",
    "    im = H5Reader(im).Img[ROI]\n",
    "    #im = imNorm(im)\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    msk = truth[63 - ROI[0].start]\n",
    "    #msk = msk != 0\n",
    "    #msk = msk > np.percentile(msk[msk > 0].flat, maskThresh)\n",
    "    msk = flatMask(msk, thresh=40)\n",
    "    plt.subplot(131); imshow(msk)\n",
    "    #print(indices)\n",
    "    plt.subplot(132); imshow(im[63 - ROI[0].start])\n",
    "    plt.subplot(133); imshow(im[63 - ROI[0].start] * msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = sorted(glob(\"output/*/*_0_*_001.mat\"), key=path.getmtime)[-1]\n",
    "\n",
    "#imGnd = glob(\"output/?/*e+08*_000.mat\")[-1]\n",
    "imGnd = getGnd(im)\n",
    "ROI = autoROI(H5Reader(imGnd).tAct[:])  # non-zero ROI\n",
    "ims = im[:-7] + \"*.mat\"\n",
    "print(ims)\n",
    "ims = glob(ims)\n",
    "assert all([im[:-7] == i[:-7] for i in ims])\n",
    "\n",
    "# PET truth\n",
    "imGnd = H5Reader(imGnd)\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "#imGnd = imNorm(imGnd)\n",
    "step = 1\n",
    "print([i[-7:-4] for i in ims[::step]])\n",
    "#ims = [imNorm(H5Reader(i).Img[ROI]) for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [H5Reader(i).Img[ROI] for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [imGnd] + ims\n",
    "\n",
    "# imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "mask = flatMask(imGnd, maskThresh)\n",
    "imGnd = imGnd[mask]\n",
    "imScale = (imGnd ** 2).mean()\n",
    "l = len(ims)\n",
    "plt.figure(figsize=(14, 14))\n",
    "for i, im in enumerate(ims):\n",
    "    nrmse = (((im[mask] - imGnd) ** 2).mean() / imScale) ** 0.5\n",
    "    plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    imshow(im[63], vmin=0, vmax=imGnd.max(),\n",
    "           title=\"{:03d} {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plt.figure(figsize=(14, 14))\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, im in enumerate(tqdm(ims)):\n",
    "    nrmse = ((im[mask] - imGnd) ** 2).mean() / imScale\n",
    "    #plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(im.flat, bins=50)\n",
    "    plt.title(\"it {} NRMSE {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set of realisations\n",
    "fn = deepcopy(fPartsGlob)\n",
    "fn[fPartsKeys.index(\"rm\")] = rms[0]\n",
    "fn[fPartsKeys.index(\"pat\")] = pats[0]\n",
    "fn[fPartsKeys.index(\"counts\")] = counts[1]\n",
    "fn[fPartsKeys.index(\"tum\")] = tums[0]\n",
    "fn[fPartsKeys.index(\"it\")] = \"001\"\n",
    "reals = glob(\"output/?/\" + ''.join(fn))\n",
    "\n",
    "# get corresponding ground truth\n",
    "imGnd = H5Reader(getGnd(reals[-1]))\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "\n",
    "# produce mask\n",
    "#mask = imGnd > np.percentile(imGnd[imGnd > imGnd.min()].flat, 99.9)\n",
    "mask = flatMask(imGnd)\n",
    "print(mask.sum(), \"pixels\")\n",
    "#plt.subplot(121); imshow(mask[len(mask) // 2])\n",
    "#plt.subplot(122); imshow(imGnd[len(mask) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rizyx = [RE_INFO.findall(i)[0] for i in reals]\n",
    "rizyx = [[j for j in glob(i.replace(\"_001.mat\", \"_*.mat\"))\n",
    "          if not j.endswith(\"_000.mat\")]\n",
    "         for i in reals]\n",
    "irzyx = np.array(rizyx).T\n",
    "\n",
    "#RE_INFO.findall(reals[0])[0]\n",
    "#rizyx = [i.replace(\"\") for i in glob(fns) if \"_001.mat\" in i]\n",
    "\n",
    "step = 5\n",
    "irzyx = irzyx[::step]\n",
    "\n",
    "l = len(irzyx)\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, it in enumerate(tqdm(irzyx)):\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(np.array([H5Reader(im).Img[ROI][mask] for im in it]).flat)\n",
    "    plt.title(str((i - 1) * step + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
