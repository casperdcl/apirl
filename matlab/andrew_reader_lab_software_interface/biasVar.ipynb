{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import re\n",
    "from os import path\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.simplefilter(\"ignore\", category=TqdmExperimentalWarning)\n",
    "    from tqdm.auto import tqdm, trange\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"numpy.dtype size changed\", module=\"h5py\")\n",
    "from caspyr.utils import H5Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, cmap=\"Greys\", origin=\"lower\", title=None, **kwargs):\n",
    "    ax = plt.imshow(im, cmap=cmap, origin=origin, **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "def autoROI(im):\n",
    "    \"\"\"return bounding box tuple(slice) of non-zero elements\"\"\"\n",
    "    inds = np.array(im.nonzero())\n",
    "    mins = inds.min(axis=1)\n",
    "    maxs = inds.max(axis=1)\n",
    "    return tuple(slice(i, j) for i, j in zip(mins, maxs))\n",
    "\n",
    "def imNorm(im, assumeZeroMin=True):\n",
    "    \"\"\"in-place, average 1 count/voxel\"\"\"\n",
    "    if not assumeZeroMin:\n",
    "        im -= im.min()\n",
    "    im *= im.size / im.max()\n",
    "    return im\n",
    "\n",
    "def flatMask(im, thresh=50, hw=1):\n",
    "    \"\"\"\n",
    "    thresh  : int, percentile\n",
    "    hw  : int, half width\n",
    "    \"\"\"\n",
    "    from scipy.signal import convolve\n",
    "    m = np.ones([2*hw+1] * im.ndim) * -1\n",
    "    m[hw, hw] = m.size - 1\n",
    "    edges = np.abs(convolve(im, m, mode='same'))\n",
    "    msk = edges < np.percentile(edges.flat, thresh)  # high pass\n",
    "    msk *= im > np.percentile(im[im > 0].flat, 100 - thresh)  # low pass\n",
    "    return msk\n",
    "\n",
    "class Globber(object):\n",
    "    def __init__(self, *parts):\n",
    "        \"\"\"\n",
    "        parts  : (tuple(name, regex, glob), ...)\n",
    "        \"\"\"\n",
    "        self.partsKeys = [i[0] for i in parts]\n",
    "        self.partsVals = [i[1] for i in parts]\n",
    "        self.partsGlob = [i[2] for i in parts]\n",
    "        self.val = self.parseRe()\n",
    "        self.valRe = re.compile(self.val)\n",
    "        self.glb = self.parseGlob()\n",
    "        # glob all files\n",
    "        self.files = self.glob(self.glb)\n",
    "        # ensure files pass the regex\n",
    "        self.files = self.filterRe()\n",
    "\n",
    "    def filterGlob(self, **keys):\n",
    "        \"\"\"return self.files that match given key=glob pairs\"\"\"\n",
    "        raise DeprecationWarning\n",
    "        p = deepcopy(self.partsGlob)\n",
    "        for k, v in keys.items():\n",
    "            p[self.index(k)] = v\n",
    "        return self.filterRe(self.glob(self.parseGlob(p)))\n",
    "\n",
    "    def filterRe(self, **keys):\n",
    "        \"\"\"return self.files that match given key=regex pairs\"\"\"\n",
    "        p = deepcopy(self.partsVals)\n",
    "        for k, v in keys.items():\n",
    "            p[self.index(k)] = v\n",
    "        r = re.compile(self.parseRe(p))\n",
    "        return filter(r.match, self.files)\n",
    "\n",
    "    def filterReLike(self, fname, **keys):\n",
    "        \"\"\"return self.files that are like `fname` but with given key=regex pairs\n",
    "\n",
    "        Use `None` for regex for default (all)\"\"\"\n",
    "        p = self.valRe.findall(fname)[0]\n",
    "        for k, v in keys.items():\n",
    "            p[self.index(k)] = self.partsVals[self.index(k)] if v is None else v\n",
    "        r = re.compile(self.parseRe(p))\n",
    "        return filter(r.match, self.files)\n",
    "\n",
    "    def index(self, key):\n",
    "        return self.partsKeys.index(key)\n",
    "\n",
    "    def parseGlob(self, parts=None):\n",
    "        return ''.join(self.partsGlob if parts is None else parts)\n",
    "\n",
    "    def parseRe(self, parts=None):\n",
    "        return ''.join('(' + i + ')' for i in\n",
    "                       (self.partsVals if parts is None else parts))\n",
    "\n",
    "    @classmethod\n",
    "    def glob(cls, *a, **k):\n",
    "        \"\"\"sorted version of glob.glob\"\"\"\n",
    "        from glob import glob as g\n",
    "        return sorted(g(*a, **k))\n",
    "\n",
    "def glob(*a, **k):\n",
    "    return Globber.glob(*a, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globber = Globber(\n",
    "    (\"meta0\", \"output/[0-9]+/brainweb_\", \"output/*/brainweb_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_[0-9]+_subject_\", \"_*_subject_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta6\", \"-S_\", \"-S_\"),\n",
    "    (\"sigma\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta7\", \"-NP_\", \"-NP_\"),\n",
    "    (\"fsPET\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta8\", \"-NT1_\", \"-NT1_\"),\n",
    "    (\"fsT1\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"[-0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, regex, glob\n",
    "fParts = (\n",
    "    (\"meta0\", \".*brainweb_\", \"*brainweb_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_[0-9]+_subject_\", \"_*_subject_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta6\", \"-S_\", \"-S_\"),\n",
    "    (\"sigma\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta7\", \"-NP_\", \"-NP_\"),\n",
    "    (\"fsPET\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta8\", \"-NT1_\", \"-NT1_\"),\n",
    "    (\"fsT1\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"[-0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))\n",
    "fPartsKeys = [i[0] for i in fParts]\n",
    "fPartsVals = [i[1] for i in fParts]\n",
    "fPartsGlob = [i[2] for i in fParts]\n",
    "RE_INFO = ''.join('(' + i + ')' for i in fPartsVals)\n",
    "RE_INFO = re.compile(RE_INFO)\n",
    "FOLDERS = 8\n",
    "maskThresh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGnd(fn, debug=False):\n",
    "    # ground truth image\n",
    "    p = list(RE_INFO.findall(fn)[0])\n",
    "    p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "    #p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "    p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "    p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "    for c in \"0123456789\":\n",
    "      p[fPartsKeys.index(\"meta0\")] = p[fPartsKeys.index(\"meta0\")].replace(\"/%s/\" % c, \"/*/\")\n",
    "    p = ''.join(p)\n",
    "    files = glob(p)\n",
    "    if not files:\n",
    "        raise IOError(\"Could not find:\" + p)\n",
    "    if debug:\n",
    "        ROI = autoROI(H5Reader(files[0]).tAct[:])  # non-zero ROI\n",
    "        imGnd = H5Reader(files[0]).tAct[ROI]\n",
    "        tmp = [(imGnd == H5Reader(i).tAct[ROI]).all() for i in tqdm(files, desc=\"debug\")]\n",
    "        #print(len(tmp), files)\n",
    "        if not all(tmp):\n",
    "            raise ValueError(\"mismatched ground truths:\" + p)\n",
    "    return files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([fn for i in range(FOLDERS) for fn in glob(\"output/%d/brain*_001.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "\n",
    "rms = sorted({i[fPartsKeys.index(\"rm\")] for i in parts})\n",
    "pats = sorted({i[fPartsKeys.index(\"pat\")] for i in parts}, key=int)\n",
    "counts = sorted({i[fPartsKeys.index(\"counts\")] for i in parts}, key=float)\n",
    "tums = sorted({i[fPartsKeys.index(\"tum\")] for i in parts}, key=int)\n",
    "its = sorted({i[fPartsKeys.index(\"it\")] for i in parts}, key=int)\n",
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varDict = {}\n",
    "bsqDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputPkl = \"output/biasVar.pkl\"\n",
    "#outputPkl = \"output/biasVar-flat.pkl\"\n",
    "outputPkl = \"output/biasVar-brainweb.pkl\"\n",
    "with open(outputPkl) as fd:\n",
    "    bsqDict, varDict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "fn = deepcopy(fPartsGlob)\n",
    "for rm in tqdm(rms, desc=\"RM\"):\n",
    "    fn[fPartsKeys.index(\"rm\")] = rm\n",
    "    for pat in tqdm(pats, desc=\"Patient\"):\n",
    "        fn[fPartsKeys.index(\"pat\")] = pat\n",
    "        for cnt in tqdm(counts, desc=\"Counts\"):\n",
    "            fn[fPartsKeys.index(\"counts\")] = cnt\n",
    "            for tum in tqdm(tums, desc=\"Tumours\"):\n",
    "                fn[fPartsKeys.index(\"tum\")] = tum\n",
    "                files = glob(\"output/[%s]/%s\" % (''.join(map(str, range(FOLDERS))), ''.join(fn)))\n",
    "                if not files:\n",
    "                    continue\n",
    "                #print(len(files))\n",
    "                #print('\\n'.join(files))\n",
    "                parts = [RE_INFO.findall(i)[0] for i in files]\n",
    "                #print(len(parts))\n",
    "                parts = sorted({i[:-2] + (\"\",) + i[-1:] for i in parts})  # ignore iteration\n",
    "                print('\\n'.join([''.join(i) for i in parts]))\n",
    "                parts = [list(p) for p in parts]\n",
    "                #print('\\n'.join(':'.join(i) for i in parts))\n",
    "                # per-iteration results vectors\n",
    "                bsq = []\n",
    "                var = []\n",
    "                # ground truth image\n",
    "                imGnd = H5Reader(getGnd(files[0]))\n",
    "                ROI = autoROI(imGnd.tAct[:])  # non-zero ROI\n",
    "                imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "                print(\"counts:%.3g\" % imGnd.sum())\n",
    "                #imGnd = imNorm(imGnd)\n",
    "                # imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "                ####mask = flatMask(imGnd, maskThresh)\n",
    "                mask = imGnd > 0\n",
    "                imGnd = imGnd[mask]\n",
    "                imScale = (imGnd ** 2).mean()\n",
    "                # pre-allocate one set of realisations [R, X, Y, Z]\n",
    "                #ims = np.zeros((len(parts),) + imGnd.shape, dtype=imGnd.dtype)\n",
    "                ims = np.zeros((len(parts), imGnd.size), dtype=imGnd.dtype)\n",
    "                with trange(1, 1 + (300 if \"psf\" in rm else 100),\n",
    "                                 desc=\"%d reals iter\" % len(parts)) as tIters:\n",
    "                  for it in tIters:\n",
    "                    for i, p in enumerate(tqdm(parts, desc=\"realisations\", disable=True)):\n",
    "                        p[-2] = \"%03d\" % it\n",
    "                        #ims[i] = imNorm(H5Reader(''.join(p)).Img[ROI])[mask]\n",
    "                        ims[i] = H5Reader(''.join(p)).Img[ROI][mask]\n",
    "                    imMean = ims.mean(axis=0)\n",
    "                    #bsq.append(((imMean - imGnd) / imGnd).mean())\n",
    "                    #var.append((np.std(ims, axis=0, ddof=1) / imMean).mean())\n",
    "                    bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                    var.append((np.var(ims, axis=0, ddof=1)).mean() / imScale)\n",
    "                    tIters.set_postfix(\n",
    "                        # N.B: mseTest will be nonzero due to var(..., ddof=1)\n",
    "                        # mseTest = ((ims - imGnd) ** 2).mean() / imScale - bsq[-1] - var[-1],\n",
    "                        mse=bsq[-1] + var[-1], bsq=bsq[-1], var=var[-1], refresh=False)\n",
    "                bsqDict[':'.join(parts[0])] = bsq\n",
    "                varDict[':'.join(parts[0])] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    with open(outputPkl, \"w\") as fd:\n",
    "        pickle.dump((bsqDict, varDict), fd, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(sorted(varDict.keys())))\n",
    "rmPatCnt = []\n",
    "for rm, pat, cnt in {(i[fPartsKeys.index(\"rm\")], i[fPartsKeys.index(\"pat\")], i[fPartsKeys.index(\"counts\")])\n",
    "                   for k in varDict.keys() for i in [k.split(\":\")]}:\n",
    "    avgBiasVar = [\n",
    "        np.array([src[k] for k in src for i in [k.split(':')]\n",
    "                  if i[fPartsKeys.index(\"rm\")]==rm\n",
    "                  and i[fPartsKeys.index(\"pat\")]==pat\n",
    "                  and i[fPartsKeys.index(\"counts\")]==cnt]).mean(axis=0)\n",
    "        for src in (bsqDict, varDict)]\n",
    "    rmPatCnt.append((rm, pat, cnt, avgBiasVar))\n",
    "    #rmPatCnt.setdefault(i1, {}).setdefault(i3, {})[float(i5)] = res.mean(axis=0)\n",
    "rmPatCnt.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = sorted({i[1] for i in rmPatCnt})\n",
    "for pat in pats:\n",
    "  plt.figure()\n",
    "  plt.title(\"Train\" if pat == pats[0] else \"Validation\")\n",
    "  for rm, patM, cnt, (bsq, var) in rmPatCnt:\n",
    "    mcnt = float(cnt) / 1e6\n",
    "    if patM == pat:\n",
    "      #ls = '+' if \"psf\" in rm else 'x'\n",
    "      ls = ':' if mcnt <= 43 else '-'\n",
    "      #nbias, nstd = [i ** 0.5 * 100 for i in (bsq, var)]\n",
    "      y = (np.array(bsq) + var) ** 0.5 * 100  # NRMSE\n",
    "      i = y.argmin()  # index of minimal NRMSE\n",
    "      #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "      #y = 10 * np.log10(y / 100.0)\n",
    "      plt.plot(range(len(y)), y, ls,\n",
    "               label=\"MLEM{psf} {mcnt:.0f}M count (min NRMSE at {i}/{nit} iters)\".format(\n",
    "                   psf=\"+RM\" if \"psf\" in rm else \"\", mcnt=mcnt, i=i + 1, nit=len(y)))\n",
    "      plt.plot([i], y[i:i+1], 'ko', ms=6)\n",
    "  plt.xlabel(r\"Iteration\")\n",
    "  plt.ylabel(\"NRMSE/[%]\")\n",
    "  plt.ylim(0, 200)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "rImgDir = path.join(\"output\", \"maskThresh\", str(maskThresh))\n",
    "if not path.exists(rImgDir):\n",
    "  os.mkdir(rImgDir)\n",
    "\n",
    "for k1 in sorted(varDict.keys(), key=lambda x: x.split(':')):\n",
    " if ':3.01e+08:' in k1:\n",
    "  plt.figure()\n",
    "  plt.title(k1)\n",
    "  for k, ls in zip([k1, k1.replace(':3.01e+08:', ':4.3e+07:')], ['x-', 'o-']):\n",
    "    y, x = [np.array(d[k]) ** 0.5 * 100 for d in (bsqDict, varDict)]\n",
    "    i = (x + y).argmin()  # index of minimal NRMSE\n",
    "    # plt.title(\"MLEM {k[5]} count, {k[9]} iters (min NRMSE at {i})\".format(k=k.split(':'), i=i + 1))\n",
    "    #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "    #y = 10 * np.log10(y / 100.0)\n",
    "    meta = k.split(':')\n",
    "    meta[fPartsKeys.index(\"rm\")] = \"+RM\" if meta[fPartsKeys.index(\"rm\")][3:] else \"\"\n",
    "    meta[fPartsKeys.index(\"counts\")] = float(meta[fPartsKeys.index(\"counts\")]) / 1e6\n",
    "    plt.plot(x, y, ls, label=(\"MLEM{k[\" +\n",
    "                              str(fPartsKeys.index(\"rm\")) +\n",
    "                              \"]} {k[\" +\n",
    "                              str(fPartsKeys.index(\"counts\")) +\n",
    "                              \"]:.0f}M count (min NRMSE at {i}/{k[\" +\n",
    "                              str(fPartsKeys.index(\"it\")) +\n",
    "                              \"]} iters)\").format(\n",
    "        k=meta, i=i + 1))\n",
    "    plt.plot(x[i:i+1], y[i:i+1], 'ro', ms=6)\n",
    "  plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "  plt.ylabel(\"Bias/[%]\")\n",
    "  plt.ylim(0, None)\n",
    "  plt.xlim(0, None)\n",
    "  #plt.axes().set_aspect('equal')\n",
    "  plt.legend()\n",
    "  plt.savefig(path.join(rImgDir, re.sub(r\"\\W\", '', k1)) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in varDict.keys()], key=lambda x: x.split(':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([fn for i in range(FOLDERS)\n",
    "                for fn in glob(\"output/%d/*_300.mat\" % i) + glob(\"output/%d/*_PET_*_100.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "print(len(parts))\n",
    "for p in tqdm(parts[:1]):\n",
    "    im = ''.join(p)\n",
    "    truth = getGnd(im, debug=True)\n",
    "    print(truth, '\\n', im)\n",
    "    # load\n",
    "    ROI = autoROI(H5Reader(truth).tAct[:])\n",
    "    print(ROI)\n",
    "    ##print(H5Reader(truth).tAct.shape)\n",
    "    truth = H5Reader(truth)\n",
    "    truth = truth.tAct[ROI] * truth.scale_factor[0, 0]\n",
    "    #truth = imNorm(truth)\n",
    "    ##print(H5Reader(im).Img.shape)\n",
    "    im = H5Reader(im).Img[ROI]\n",
    "    #im = imNorm(im)\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    msk = truth[63 - ROI[0].start]\n",
    "    #msk = msk != 0\n",
    "    #msk = msk > np.percentile(msk[msk > 0].flat, maskThresh)\n",
    "    msk = flatMask(msk, thresh=40)\n",
    "    plt.subplot(131); imshow(msk)\n",
    "    #print(indices)\n",
    "    plt.subplot(132); imshow(im[63 - ROI[0].start])\n",
    "    plt.subplot(133); imshow(im[63 - ROI[0].start] * msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = sorted(glob(\"output/*/*_0_*_001.mat\"), key=path.getmtime)[-1]\n",
    "\n",
    "#imGnd = glob(\"output/?/*e+08*_000.mat\")[-1]\n",
    "imGnd = getGnd(im)\n",
    "ROI = autoROI(H5Reader(imGnd).tAct[:])  # non-zero ROI\n",
    "ims = im[:-7] + \"*.mat\"\n",
    "print(ims)\n",
    "ims = glob(ims)\n",
    "assert all([im[:-7] == i[:-7] for i in ims])\n",
    "\n",
    "# PET truth\n",
    "imGnd = H5Reader(imGnd)\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "#imGnd = imNorm(imGnd)\n",
    "step = 1\n",
    "print([i[-7:-4] for i in ims[::step]])\n",
    "#ims = [imNorm(H5Reader(i).Img[ROI]) for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [H5Reader(i).Img[ROI] for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [imGnd] + ims\n",
    "\n",
    "# imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "mask = flatMask(imGnd, maskThresh)\n",
    "imGnd = imGnd[mask]\n",
    "imScale = (imGnd ** 2).mean()\n",
    "l = len(ims)\n",
    "plt.figure(figsize=(14, 14))\n",
    "for i, im in enumerate(ims):\n",
    "    nrmse = (((im[mask] - imGnd) ** 2).mean() / imScale) ** 0.5\n",
    "    plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    imshow(im[63], vmin=0, vmax=imGnd.max(),\n",
    "           title=\"{:03d} {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plt.figure(figsize=(14, 14))\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, im in enumerate(tqdm(ims)):\n",
    "    nrmse = ((im[mask] - imGnd) ** 2).mean() / imScale\n",
    "    #plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(im.flat, bins=50)\n",
    "    plt.title(\"it {} NRMSE {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set of realisations\n",
    "fn = deepcopy(fPartsGlob)\n",
    "fn[fPartsKeys.index(\"rm\")] = rms[0]\n",
    "fn[fPartsKeys.index(\"pat\")] = pats[0]\n",
    "fn[fPartsKeys.index(\"counts\")] = counts[1]\n",
    "fn[fPartsKeys.index(\"tum\")] = tums[0]\n",
    "fn[fPartsKeys.index(\"it\")] = \"001\"\n",
    "reals = glob(\"output/?/\" + ''.join(fn))\n",
    "\n",
    "# get corresponding ground truth\n",
    "imGnd = H5Reader(getGnd(reals[-1]))\n",
    "imGnd = imGnd.tAct[ROI] * imGnd.scale_factor[0, 0]\n",
    "\n",
    "# produce mask\n",
    "#mask = imGnd > np.percentile(imGnd[imGnd > imGnd.min()].flat, 99.9)\n",
    "mask = flatMask(imGnd)\n",
    "print(mask.sum(), \"pixels\")\n",
    "#plt.subplot(121); imshow(mask[len(mask) // 2])\n",
    "#plt.subplot(122); imshow(imGnd[len(mask) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rizyx = [RE_INFO.findall(i)[0] for i in reals]\n",
    "rizyx = [[j for j in glob(i.replace(\"_001.mat\", \"_*.mat\"))\n",
    "          if not j.endswith(\"_000.mat\")]\n",
    "         for i in reals]\n",
    "irzyx = np.array(rizyx).T\n",
    "\n",
    "#RE_INFO.findall(reals[0])[0]\n",
    "#rizyx = [i.replace(\"\") for i in glob(fns) if \"_001.mat\" in i]\n",
    "\n",
    "step = 5\n",
    "irzyx = irzyx[::step]\n",
    "\n",
    "l = len(irzyx)\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, it in enumerate(tqdm(irzyx)):\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(np.array([H5Reader(im).Img[ROI][mask] for im in it]).flat)\n",
    "    plt.title(str((i - 1) * step + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
