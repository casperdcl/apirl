{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from glob import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import re\n",
    "\n",
    "from caspyr.utils import H5Reader\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, regex, glob\n",
    "fParts = (\n",
    "    (\"meta0\", \".*real_\", \"*real_\"),\n",
    "    (\"rm\", \"PET|PETpsf\", \"PET*\"),\n",
    "    (\"meta1\", \"_nosharp_[0-9]+_AD_\", \"_nosharp_*_AD_\"),\n",
    "    (\"pat\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta2\", \"-C_\", \"-C_\"),\n",
    "    (\"counts\", \"[0-9.e+]+\", \"*\"),\n",
    "    (\"meta3\", \"_t\", \"_t\"),\n",
    "    (\"tum\", \"[-0-9]+\", \"*\"),\n",
    "    (\"meta4\", \"_\", \"_\"),\n",
    "    (\"it\", \"[0-9]+\", \"*\"),\n",
    "    (\"meta5\", r\"\\.mat\", \".mat\"))\n",
    "fPartsKeys = [i[0] for i in fParts]\n",
    "fPartsVals = [i[1] for i in fParts]\n",
    "fPartsGlob = [i[2] for i in fParts]\n",
    "RE_INFO = ''.join('(' + i + ')' for i in fPartsVals)\n",
    "RE_INFO = re.compile(RE_INFO)\n",
    "FOLDERS = 7\n",
    "maskThresh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoROI(im):\n",
    "    \"\"\"return bounding box tuple(slice) of non-zero elements\"\"\"\n",
    "    inds = np.array(im.nonzero())\n",
    "    mins = inds.min(axis=1)\n",
    "    maxs = inds.max(axis=1)\n",
    "    return tuple(slice(i, j) for i, j in zip(mins, maxs))\n",
    "\n",
    "\n",
    "def imNorm(im, assumeZeroMin=True):\n",
    "    \"\"\"in-place, average 1 count/voxel\"\"\"\n",
    "    if not assumeZeroMin:\n",
    "        im -= im.min()\n",
    "    im *= im.size / im.max()\n",
    "    return im\n",
    "\n",
    "\n",
    "def flatMask(im, thresh=50, hw=1):\n",
    "    \"\"\"\n",
    "    thresh  : int, percentile\n",
    "    hw  : int, half width\n",
    "    \"\"\"\n",
    "    from scipy.signal import convolve\n",
    "    m = np.ones([2*hw+1] * im.ndim) * -1\n",
    "    m[hw, hw] = m.size - 1\n",
    "    edges = np.abs(convolve(im, m, mode='same'))\n",
    "    msk = edges < np.percentile(edges.flat, thresh)  # high pass\n",
    "    msk *= im > np.percentile(im[im > 0].flat, 100 - thresh)  # low pass\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([fn for i in range(FOLDERS) for fn in glob(\"output/%d/*.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "\n",
    "rms = sorted({i[fPartsKeys.index(\"rm\")] for i in parts})\n",
    "pats = sorted({i[fPartsKeys.index(\"pat\")] for i in parts}, key=int)\n",
    "counts = sorted({i[fPartsKeys.index(\"counts\")] for i in parts}, key=float)\n",
    "tums = sorted({i[fPartsKeys.index(\"tum\")] for i in parts}, key=int)\n",
    "its = sorted({i[fPartsKeys.index(\"it\")] for i in parts}, key=int)\n",
    "print(rms, pats, counts, tums)  # , its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#varDict = {}\n",
    "#bsqDict = {}\n",
    "\n",
    "# biasVar-flat\n",
    "# biasVar\n",
    "with open(\"output/biasVar.pkl\") as fd:\n",
    "    bsqDict, varDict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "fn = deepcopy(fPartsGlob)\n",
    "for rm in tqdm(rms, desc=\"RM\"):\n",
    "    fn[fPartsKeys.index(\"rm\")] = rm\n",
    "    for pat in tqdm(pats, desc=\"Patient\"):\n",
    "        fn[fPartsKeys.index(\"pat\")] = pat\n",
    "        for cnt in tqdm(counts, desc=\"Counts\"):\n",
    "            fn[fPartsKeys.index(\"counts\")] = cnt\n",
    "            for tum in tqdm(tums, desc=\"Tumours\"):\n",
    "                fn[fPartsKeys.index(\"tum\")] = tum\n",
    "                files = sorted(glob(\"output/[%s]/%s\" % (''.join(map(str, range(FOLDERS))), ''.join(fn))))\n",
    "                if not files:\n",
    "                    continue\n",
    "                #print(len(files))\n",
    "                #print('\\n'.join(files))\n",
    "                parts = [RE_INFO.findall(i)[0] for i in files]\n",
    "                #print(len(parts))\n",
    "                parts = sorted({i[:-2] + (\"\",) + i[-1:] for i in parts})  # ignore iteration\n",
    "                parts = [list(p) for p in parts]\n",
    "                #print('\\n'.join(':'.join(i) for i in parts))\n",
    "                # per-iteration results vectors\n",
    "                bsq = []\n",
    "                var = []\n",
    "                # ground truth image\n",
    "                p = deepcopy(parts[0])  # first realisation\n",
    "                p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "                p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "                p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "                p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "                p = ''.join(p)\n",
    "                if not glob(p):\n",
    "                    raise IOError(\"Could not find \" + p)\n",
    "                if False:  # TEST\n",
    "                    ROI = autoROI(H5Reader(glob(p)[0]).tAct[:])  # non-zero ROI\n",
    "                    imGnd = imNorm(H5Reader(glob(p)[0]).tAct[ROI])\n",
    "                    tmp = [(imGnd == imNorm(H5Reader(i).tAct[ROI])).all() for i in glob(p)]\n",
    "                    #print(len(tmp), glob(p))\n",
    "                    assert all(tmp)\n",
    "                    #continue\n",
    "                p = glob(p)[0]\n",
    "                ROI = autoROI(H5Reader(p).tAct[:])  # non-zero ROI\n",
    "                imGnd = imNorm(H5Reader(p).tAct[ROI])  # PET truth\n",
    "                # imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "                mask = flatMask(imGnd, maskThresh)\n",
    "                imGnd = imGnd[mask]\n",
    "                imScale = (imGnd ** 2).mean()\n",
    "                # pre-allocate one set of realisations [R, X, Y, Z]\n",
    "                #ims = np.zeros((len(parts),) + imGnd.shape, dtype=imGnd.dtype)\n",
    "                ims = np.zeros((len(parts), imGnd.size), dtype=imGnd.dtype)\n",
    "                with trange(1, 1 + (300 if \"psf\" in rm else 100),\n",
    "                                 desc=\"%d reals iter\" % len(parts)) as tIters:\n",
    "                  for it in tIters:\n",
    "                    for i, p in enumerate(tqdm(parts, desc=\"realisations\", disable=True)):\n",
    "                        p[-2] = \"%03d\" % it\n",
    "                        ims[i] = imNorm(H5Reader(''.join(p)).Img[ROI])[mask]\n",
    "                    imMean = ims.mean(axis=0)\n",
    "                    #bsq.append(((imMean - imGnd) / imGnd).mean())\n",
    "                    #var.append((np.std(ims, axis=0, ddof=1) / imMean).mean())\n",
    "                    bsq.append(((imMean - imGnd) ** 2).mean() / imScale)\n",
    "                    var.append((np.var(ims, axis=0, ddof=1)).mean() / imScale)\n",
    "                    tIters.set_postfix(\n",
    "                        # N.B: mseTest will be nonzero due to var(..., ddof=1)\n",
    "                        # mseTest = ((ims - imGnd) ** 2).mean() / imScale - bsq[-1] - var[-1],\n",
    "                        mse=bsq[-1] + var[-1], bsq=bsq[-1], var=var[-1], refresh=False)\n",
    "                bsqDict[':'.join(parts[0])] = bsq\n",
    "                varDict[':'.join(parts[0])] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biasVar\n",
    "# biasVar-flat\n",
    "if 0:\n",
    "    with open(\"output/biasVar-flat.pkl\", \"w\") as fd:\n",
    "        pickle.dump((bsqDict, varDict), fd, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(varDict.keys()))\n",
    "rmPatCnt = []\n",
    "for i1, i3, i5 in {(i[1], i[3], i[5]) for k in sorted(varDict.keys()) for i in [k.split(\":\")]}:\n",
    "    avgBiasVar = [\n",
    "        np.array([src[k] for k in src for i in [k.split(':')] if i[1]==i1 and i[3]==i3 and i[5]==i5]).mean(axis=0)\n",
    "        for src in (bsqDict, varDict)]\n",
    "    rmPatCnt.append((i1, i3, i5, avgBiasVar))\n",
    "    #rmPatCnt.setdefault(i1, {}).setdefault(i3, {})[float(i5)] = res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = sorted({i[1] for i in rmPatCnt})\n",
    "for pat in pats:\n",
    "  plt.figure()\n",
    "  plt.title(\"Train\" if pat == \"1\" else \"Validation\")\n",
    "  for rm, patM, cnt, (bsq, var) in rmPatCnt:\n",
    "    mcnt = float(cnt) / 1e6\n",
    "    if patM == pat:\n",
    "      #ls = '+' if \"psf\" in rm else 'x'\n",
    "      ls = ':' if mcnt <= 43 else '-'\n",
    "      y, x = [i ** 0.5 * 100 for i in (bsq, var)]\n",
    "      #y = x  # std\n",
    "      y = np.hypot(y, x)  # NRMSE\n",
    "      i = y.argmin()  # index of minimal NRMSE\n",
    "      #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "      #y = 10 * np.log10(y / 100.0)\n",
    "      plt.plot(range(len(x)), y, ls,\n",
    "               label=\"MLEM{psf} {mcnt:.0f}M count (min NRMSE at {i}/{nit} iters)\".format(\n",
    "                   psf=\"+RM\" if \"psf\" in rm else \"\", mcnt=mcnt, i=i + 1, nit=len(y)))\n",
    "      plt.plot([i], y[i:i+1], 'ko', ms=6)\n",
    "  plt.xlabel(r\"Iteration\")\n",
    "  plt.ylabel(\"NRMSE/[%]\")\n",
    "  plt.ylim(0, 200)\n",
    "  plt.xlim(0, None)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "rImgDir = path.join(\"output\", \"maskThresh\", str(maskThresh))\n",
    "if not path.exists(rImgDir):\n",
    "  os.mkdir(rImgDir)\n",
    "\n",
    "for k1 in sorted(varDict.keys(), key=lambda x: x.split(':')):\n",
    " if ':3.01e+08:' in k1:\n",
    "  plt.figure()\n",
    "  plt.title(k1)\n",
    "  for k, ls in zip([k1, k1.replace(':3.01e+08:', ':4.3e+07:')], ['x-', 'o-']):\n",
    "    y, x = [np.array(d[k]) ** 0.5 * 100 for d in (bsqDict, varDict)]\n",
    "    i = (x + y).argmin()  # index of minimal NRMSE\n",
    "    # plt.title(\"MLEM {k[5]} count, {k[9]} iters (min NRMSE at {i})\".format(k=k.split(':'), i=i + 1))\n",
    "    #plt.ticklabel_format(style=\"sci\", scilimits=(-3, 3))\n",
    "    #y = 10 * np.log10(y / 100.0)\n",
    "    meta = k.split(':')\n",
    "    meta[1] = \"+RM\" if meta[1][3:] else \"\"\n",
    "    meta[5] = float(meta[5]) / 1e6\n",
    "    plt.plot(x, y, ls, label=\"MLEM{k[1]} {k[5]:.0f}M count (min NRMSE at {i}/{k[9]} iters)\".format(\n",
    "        k=meta, i=i + 1))\n",
    "    plt.plot(x[i:i+1], y[i:i+1], 'ro', ms=6)\n",
    "  plt.xlabel(r\"Standard deviation, $\\sigma$/[%]\")\n",
    "  plt.ylabel(\"Bias/[%]\")\n",
    "  plt.ylim(0, None)\n",
    "  plt.xlim(0, None)\n",
    "  #plt.axes().set_aspect('equal')\n",
    "  plt.legend()\n",
    "  plt.savefig(path.join(rImgDir, re.sub(r\"\\W\", '', k1)) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in varDict.keys()], key=lambda x: x.split(':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PET_10 = [[r1i1, ..., r1i100], ..., [rNi1, ..., rNi100]]\n",
    "#PETpsf_10 = ...\n",
    "#PET_70 = ...\n",
    "#PETpsf_70 = ...\n",
    "PET_10 = None\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = slice(0, None), slice(100, 250), slice(100, 250)\n",
    "files = sorted([fn for i in range(FOLDERS) for fn in glob(\"output/%d/*_300.mat\" % i) + glob(\"%d/*_PET_*_100.mat\" % i)])\n",
    "parts = [RE_INFO.findall(fn)[0] for fn in files]\n",
    "print(len(parts))\n",
    "for p in tqdm(parts[:1]):\n",
    "    p = list(p)\n",
    "    im = ''.join(p)\n",
    "    p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "    p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "    p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "    p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "    truth = ''.join(p)\n",
    "    truth = glob(truth)[0]\n",
    "    print(truth, im)\n",
    "    # load\n",
    "    ROI = autoROI(H5Reader(truth).tAct[:])\n",
    "    print(ROI)\n",
    "    ##print(H5Reader(truth).tAct.shape)\n",
    "    truth = imNorm(H5Reader(truth).tAct[ROI])\n",
    "    ##print(H5Reader(im).Img.shape)\n",
    "    im = imNorm(H5Reader(im).Img[ROI])\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    msk = truth[63 - ROI[0].start]\n",
    "    #msk = msk != 0\n",
    "    #msk = msk > np.percentile(msk[msk > 0].flat, maskThresh)\n",
    "    msk = flatMask(msk, thresh=40)\n",
    "    plt.subplot(131); plt.imshow(msk)\n",
    "    #print(indices)\n",
    "    plt.subplot(132); plt.imshow(im[63 - ROI[0].start])\n",
    "    plt.subplot(133); plt.imshow(im[63 - ROI[0].start] * msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob(glob(\"6/*_001.mat\")[0].replace(\"_001.mat\", \"_*.mat\"))\n",
    "#glob(glob(\"3/*_000.mat\")[0].replace(\"_001.mat\", \"_*.mat\"))\n",
    "imGnd = glob(\"output/?/*_000.mat\")[0]\n",
    "ROI = autoROI(H5Reader(imGnd).tAct[:])  # non-zero ROI\n",
    "ims = glob(glob(\"output/?/\" + imGnd.split('/', 2)[2].replace(\"_000.mat\", \"_001.mat\"))[0].replace(\"_001.mat\", \"*.mat\"))\n",
    "\n",
    "imGnd = imNorm(H5Reader(imGnd).tAct[ROI])  # PET truth\n",
    "step = 5\n",
    "ims = [imNorm(H5Reader(i).Img[ROI]) for i in tqdm(ims[::step]) if not i.endswith(\"_000.mat\")]\n",
    "ims = [imGnd] + ims\n",
    "\n",
    "# imGnd >= np.percentile(imGnd[imGnd != 0].flat, maskThresh)\n",
    "mask = flatMask(imGnd, maskThresh)\n",
    "imGnd = imGnd[mask]\n",
    "imScale = (imGnd ** 2).mean()\n",
    "l = len(ims)\n",
    "plt.figure(figsize=(14, 14))\n",
    "for i, im in enumerate(ims):\n",
    "    nrmse = ((im[mask] - imGnd) ** 2).mean() / imScale\n",
    "    plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    plt.imshow(im[63], origin=\"lower\", cmap=\"Greys_r\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"it {} NRMSE {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(14, 14))\n",
    "_, axs = plt.subplots(int(l**.5)+1, int(l**.5)+1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "for i, im in enumerate(tqdm(ims)):\n",
    "    nrmse = ((im[mask] - imGnd) ** 2).mean() / imScale\n",
    "    #plt.subplot(l**.5+1, l**.5+1, i + 1)\n",
    "    plt.sca(axs.flat[i])\n",
    "    plt.hist(im.flat, bins=50)\n",
    "    plt.title(\"it {} NRMSE {:.3g}\".format((i - 1) * step + 1, nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a set of realisations\n",
    "fn = deepcopy(fPartsGlob)\n",
    "fn[fPartsKeys.index(\"rm\")] = rms[0]\n",
    "fn[fPartsKeys.index(\"pat\")] = pats[0]\n",
    "fn[fPartsKeys.index(\"counts\")] = counts[0]\n",
    "fn[fPartsKeys.index(\"tum\")] = tums[0]\n",
    "fn[fPartsKeys.index(\"it\")] = \"001\"\n",
    "reals = glob(\"output/?/\" + ''.join(fn))\n",
    "\n",
    "# get corresponding ground truth\n",
    "p = deepcopy(fn)\n",
    "p[fPartsKeys.index(\"rm\")] = fPartsGlob[fPartsKeys.index(\"rm\")]\n",
    "p[fPartsKeys.index(\"counts\")] = fPartsGlob[fPartsKeys.index(\"counts\")]\n",
    "#p[fPartsKeys.index(\"meta1\")] = fPartsGlob[fPartsKeys.index(\"meta1\")]\n",
    "p[fPartsKeys.index(\"it\")] = \"000\"  # 0^th iter (metadata)\n",
    "imGnd = H5Reader(glob(\"output/?/\" + ''.join(p))[0]).tAct[ROI]\n",
    "if False:  # TEST\n",
    "    assert all([(H5Reader(i).tAct[ROI] == imGnd).all()\n",
    "                for i in tqdm(glob(\"output/?/\" + ''.join(p)), desc=\"test\")])\n",
    "\n",
    "# produce mask\n",
    "mask = imGnd > np.percentile(imGnd[imGnd > imGnd.min()].flat, 99.9)\n",
    "print(mask.sum(), \"pixels\")\n",
    "#plt.subplot(121); plt.imshow(mask[len(mask) // 2])\n",
    "#plt.subplot(122); plt.imshow(imGnd[len(mask) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rizyx = [RE_INFO.findall(i)[0] for i in reals]\n",
    "rizyx = [[j for j in glob(i.replace(\"_001.mat\", \"_*.mat\"))\n",
    "          if not j.endswith(\"_000.mat\")]\n",
    "         for i in reals]\n",
    "irzyx = np.array(rizyx).T\n",
    "\n",
    "for i, rzyx in enumerate(irzyx):\n",
    "    data = np.array([H5Reader(i).Img[ROI][mask] for i in rzyx])\n",
    "    plt.hist(data.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RE_INFO.findall(reals[0])[0]\n",
    "#rizyx = [i.replace(\"\") for i in sorted(glob(fns)) if \"_001.mat\" in i]\n",
    "for it in irxyz:\n",
    "    plt.hist(it[:][mask].flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
